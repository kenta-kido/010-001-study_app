[
  {
    "id": 1,
    "questionDe": "(s2) Warum ist eine Evaluation verschiedener Methoden wichtig?",
    "questionJa": "なぜ異なる手法のEvaluation（評価）を行うことが重要なのか？",
    "answerDe": [
      "Systematischer Weg, um zu testen, wie verschiedene Methode funktionieren",
      "Vergleich zweier Methoden"
    ],
    "answerJa": [
      "さまざまな手法がどのように機能するかを体系的にテストする方法である",
      "2つの手法を比較できる"
    ],
    "explanationDe": [
      "Evaluation bedeutet, dass man verschiedene Methoden unter gleichen Bedingungen testet, um systematisch zu verstehen, wie sie funktionieren.",
      "Statt sich nur auf subjektive Eindrücke oder einzelne Beispiele zu verlassen, führt man strukturierte Tests oder Experimente durch.",
      "Zum Beispiel könnte man zwei Algorithmen für die Klassifikation medizinischer Daten vergleichen: Methode A und Methode B. Evaluation hilft dann festzustellen, welche Methode in wie vielen Fällen richtige Diagnosen liefert.",
      "So kann man objektiv entscheiden, welche Methode besser geeignet ist."
    ],
    "explanationJa": [
      "Evaluation（評価）とは、さまざまな手法を同じ条件でテストし、それぞれがどのように機能するかを体系的に理解するための方法です。",
      "主観的な印象や一部の例だけで判断するのではなく、構造化された実験や検証を行います。",
      "例えば、医療データを分類する2つのアルゴリズム（手法AとB）がある場合、Evaluationによってどちらがより正確な診断を出せるかを比較することができます。",
      "このようにして、客観的により適した手法を選ぶことが可能になります。"
    ],
    "originalSlideText": "EVALUIERUNG\n\n– Warum?\n  – Systematischer Weg, um zu testen, wie verschiedene Methode funktionieren\n  – Vergleich zweier Methoden",
    "explanationImage": "",
    "questionImage": ""
  },
  {
    "id": 2,
    "questionDe": "(s2) Welche Probleme können bei der Evaluation auftreten?",
    "questionJa": "Evaluationを行う際にどんな問題が起こりうるか？",
    "answerDe": [
      "Limitierte Datenqualität",
      "Methoden haben unterschiedliche Ergebnisse:",
      "– Klassen",
      "– Wahrscheinlichkeiten",
      "– Numerische Werte"
    ],
    "answerJa": [
      "データの質が限られている（データの信頼性や完全性が低い）",
      "手法ごとに出力される結果が異なる：",
      "– クラス（例：「はい／いいえ」などの分類）",
      "– 確率（例：「80％の確率でAに属する」）",
      "– 数値（例：スコアや連続値など）"
    ],
    "explanationDe": [
      "Ein Problem bei der Evaluation ist die begrenzte Qualität der Daten. Wenn die Daten unvollständig, verrauscht oder veraltet sind, kann das die Ergebnisse stark verzerren.",
      "Zum Beispiel: Wenn bei einem medizinischen Datensatz viele Patientenangaben fehlen, kann eine Methode schlechter bewertet werden, obwohl sie eigentlich gut ist.",
      "Ein weiteres Problem: Verschiedene Methoden liefern unterschiedliche Arten von Ergebnissen. Eine Methode gibt feste Klassen wie 'krank' oder 'gesund' aus, eine andere liefert Wahrscheinlichkeiten (z. B. 80 % für 'krank') und eine dritte liefert numerische Scores (z. B. ein Risiko-Wert von 0,73).",
      "Diese unterschiedlichen Formate machen es schwierig, die Methoden direkt zu vergleichen. Man braucht dafür angepasste Metriken."
    ],
    "explanationJa": [
      "Evaluationで問題になることの一つは、データの質が限られていることです。たとえばデータに欠損が多かったり、ノイズ（誤差）が多い場合、正確な評価ができなくなります。",
      "例として、医療データに患者情報の抜けが多いと、本来は良い手法でも正しく評価されないことがあります。",
      "また、異なる手法は異なる形式で結果を出します。ある手法は「クラス（例：病気／健康）」を返し、別の手法は「確率（例：80％病気の可能性）」、さらに別の手法は「数値（例：リスクスコア0.73）」を返すことがあります。",
      "これらの結果の形式が異なるため、同じ基準で比較するのが難しく、それぞれに合った評価指標を用意する必要があります。"
    ],
    "originalSlideText": "Probleme:\n  – Limitierte Datenqualität\n  – Methoden haben unterschiedliche Ergebnisse\n    – Klassen\n    – Wahrscheinlichkeiten\n    – Numerische Werte",
    "explanationImage": "",
    "questionImage": ""
  },
  {
    "id": 3,
    "questionDe": "(s3) Wie wird die Performanz bei Klassifizierungsproblemen gemessen und was ist das Ziel der Evaluation?",
    "questionJa": "分類問題においてパフォーマンス（性能）はどのように測定され、Evaluation（評価）の目的は何か？",
    "answerDe": [
      "Die Performanz für Klassifizierungsprobleme wird mit der Fehlerrate gemessen",
      "Fehlerrate = Anzahl der falschen Vorhersagen über alle Vorhersagen",
      "Ziel: Erreiche gute Vorhersagen auf neuen Daten"
    ],
    "answerJa": [
      "分類問題の性能は誤分類率（Fehlerrate）によって測定される",
      "誤分類率 = 全予測に対する間違った予測の割合",
      "目的：未知の新しいデータに対して良い予測ができること"
    ],
    "explanationDe": [
      "Bei Klassifizierungsproblemen geht es darum, Objekte korrekt einer Kategorie zuzuordnen, z. B. 'E-Mail' oder 'Nicht-E-Mail'.",
      "Die Fehlerrate beschreibt, wie oft das Modell eine falsche Vorhersage macht. Wenn von 100 Vorhersagen 20 falsch sind, beträgt die Fehlerrate 20 %.",
      "Ein gutes Modell sollte nicht nur auf den bereits bekannten (Trainings-)Daten funktionieren, sondern vor allem auf neuen, bisher ungesehenen Daten – das ist das Hauptziel der Evaluation.",
      "Deshalb misst man die Performanz anhand der Fehlerrate auf neuen Testdaten."
    ],
    "explanationJa": [
      "分類問題とは、たとえば「これはスパムかスパムでないか」のように、データをあるカテゴリに正しく分類する問題です。",
      "その性能（パフォーマンス）を測る指標の一つが誤分類率（Fehlerrate）で、これは全体の予測のうち、間違った予測の割合を意味します。例：100件中20件が間違い → 誤分類率20%。",
      "Evaluationの目的は、すでに学習したデータだけでなく、未知の新しいデータに対しても正確に予測できるモデルを作ることです。",
      "そのため、誤分類率は主に新しいテストデータを使って評価します。"
    ],
    "originalSlideText": "EVALUIERUNG\n\n– Training und Tests\n\n– Die Performanz für Klassifizierungsprobleme wird mit der Fehlerrate gemessen\n\n– Fehlerrate: Anzahl der falschen Vorhersagen über alle Vorhersagen\n\n– Ziel: Erreiche gute Vorhersagen auf neuen Daten",
    "explanationImage": "",
    "questionImage": ""
  },
  {
    "id": 4,
    "questionDe": "(s3) Warum ist die Fehlerrate auf dem Trainingsdatensatz kein guter Indikator und wie sollte man den Datensatz stattdessen aufteilen?",
    "questionJa": "なぜ訓練データにおける誤分類率は良い指標とは言えないのか？また、データセットはどのように分けるべきか？",
    "answerDe": [
      "Fehlerrate auf dem Trainingsdatensatz eignet sich nicht als guter Indikator",
      "Wird auch Resubstitution Fehler genannt",
      "Ist nur ein erster Indikator für die Qualität des Schätzers (Klassifizierer)",
      "Teile den Datensatz in:",
      "– Training Datensatz",
      "– Test Datensatz"
    ],
    "answerJa": [
      "訓練データでの誤分類率は良い指標ではない",
      "これは再代入誤差（Resubstitution Fehler）とも呼ばれる",
      "分類器の質を示す初期的な目安にすぎない",
      "データセットは以下のように分ける：",
      "– 訓練用データ（Training）",
      "– テスト用データ（Test）"
    ],
    "explanationDe": [
      "Wenn man die Fehlerrate nur auf dem Trainingsdatensatz misst, könnte sie sehr niedrig sein – das Modell hat aber nur 'auswendig gelernt'. Das nennt man Overfitting.",
      "Diese Fehlerrate nennt man Resubstitution Fehler, da man die gleichen Daten zum Trainieren und Testen verwendet.",
      "Sie ist kein guter Indikator für die allgemeine Qualität des Modells.",
      "Deshalb teilt man die Daten auf: Ein Teil (Trainingsdatensatz) dient zum Lernen, ein anderer Teil (Testdatensatz) zum objektiven Testen.",
      "Nur so lässt sich bewerten, wie gut das Modell auf neue Daten reagiert."
    ],
    "explanationJa": [
      "もし訓練データ（学習に使ったデータ）での誤分類率だけを見て評価すると、非常に低くなることがあります。しかしこれは、モデルが単に暗記してしまっているだけ（＝過学習）という危険があります。",
      "このような誤差は「再代入誤差（Resubstitution Fehler）」と呼ばれ、評価としては不十分です。",
      "モデルが本当に汎用性があるか（未知のデータに対してもうまく機能するか）を確かめるためには、データを「訓練用」と「テスト用」に分ける必要があります。",
      "訓練データで学習し、テストデータで評価することで、初めて本当の性能がわかります。"
    ],
    "originalSlideText": "– Die Fehlerrate auf dem Trainingsdatensatz eignet sich nicht als guter Indikator\n  – Wird auch Resubstitution Fehler genannt\n  – Ist nur ein erster Indikator für die Qualität des Schätzers (Klassifizierer)\n\n– Teile den Datensatz in\n  – Training Datensatz\n  – Test Datensatz",
    "explanationImage": "",
    "questionImage": ""
  },
  {
  "id": 5,
  "questionDe": "(s4) Warum ist es sinnvoll, verschiedene Datensätze beim Training und Testen eines Klassifizierers zu verwenden?",
  "questionJa": "分類器のトレーニングやテストにおいて、異なるデータセットを使うことがなぜ有効なのか？",
  "answerDe": [
    "Die Testdaten dürfen nicht zur Erstellung des Klassifizierers genutzt werden",
    "Nutzung von verschiedenen, unabhängigen Datensätzen ist oft sinnvoll",
    "Trainingsdatensatz: Erstelle die Regeln",
    "Validierungsdatensatz:",
    "– Pruning",
    "– Vergleich von verschiedenen Methoden"
  ],
  "answerJa": [
    "テストデータは分類器の作成には使ってはならない",
    "異なる独立したデータセットを使うのが有効な場合が多い",
    "トレーニングデータ：ルールを作成する",
    "バリデーションデータ：",
    "– 枝刈り（Pruning）",
    "– 手法の比較"
  ],
  "explanationDe": [
    "Wenn Testdaten bereits beim Trainieren des Klassifizierers verwendet werden, kann es zu Überanpassung (Overfitting) kommen – das Modell 'lernt' die Testdaten auswendig und liefert keine objektive Bewertung.",
    "Deshalb nutzt man getrennte, unabhängige Datensätze für unterschiedliche Zwecke:",
    "– Trainingsdatensatz: Dieser dient zum Erstellen des Modells, d. h. zur Erkennung von Mustern und Regeln.",
    "– Validierungsdatensatz: Wird genutzt, um das Modell während der Entwicklung zu verbessern, z. B. durch Pruning (Vereinfachung eines Entscheidungsbaums) oder zum Vergleich verschiedener Methoden.",
    "So kann man sicherstellen, dass das Modell nicht nur gut auf den Trainingsdaten funktioniert, sondern auch auf unbekannten Daten."
  ],
  "explanationJa": [
    "もしテストデータをモデルの学習に使ってしまうと、そのデータに特化してモデルが過学習してしまい、本当の性能がわからなくなります。",
    "このため、目的ごとに異なる独立したデータセットを用いることが重要です。",
    "– トレーニングデータ：モデルの規則やパターンを学習するために使います。",
    "– バリデーションデータ：学習の途中でモデルの性能を評価し、例えば決定木の枝刈り（Pruning）を行ったり、異なる手法を比較したりするために使います。",
    "これにより、モデルが未知のデータに対しても良い性能を発揮できるようになります。"
  ],
  "originalSlideText": "EVALUIERUNG\n\n– Training und Tests\n\n– Die Testdaten dürfen nicht zur Erstellung des Klassifizierers genutzt werden\n– Nutzung von verschiedenen, unabhängigen Datensätzen ist oft sinnvoll:\n  – Trainingsdatensatz: Erstelle die Regeln\n  – Validierungsdatensatz:\n    – Pruning\n    – Vergleich von verschiedenen Methoden",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 6,
  "questionDe": "(s4) Welche Rolle spielt der Testdatensatz in der Evaluation und was ist bei kleinen Datensätzen zu beachten?",
  "questionJa": "Evaluationにおけるテストデータの役割とは？また、データが少ない場合に注意すべきことは？",
  "answerDe": [
    "Testdatensatz: Test der Performanz des finalen und optimierten Klassifizierers",
    "Große Datensätze sind hier hilfreich",
    "Bei kleinen Datensätzen müssen reale Daten oft händisch klassifiziert werden"
  ],
  "answerJa": [
    "テストデータは最終的に最適化された分類器の性能評価に使う",
    "大きなデータセットがあると評価がしやすい",
    "小さなデータセットでは、実際のデータを手作業で分類する必要があることもある"
  ],
  "explanationDe": [
    "Der Testdatensatz wird ausschließlich zur abschließenden Bewertung des fertigen Klassifizierers verwendet.",
    "Er gibt Aufschluss darüber, wie gut das Modell auf völlig neue, unbekannte Daten reagiert – also in der realen Anwendung.",
    "Je größer der Testdatensatz ist, desto verlässlicher ist diese Einschätzung.",
    "Bei kleinen Datensätzen fehlt es oft an ausreichend echten Testbeispielen, weshalb man manchmal zusätzliche Daten manuell klassifizieren (also mit der Hand 'labeln') muss, um sinnvolle Evaluation durchführen zu können."
  ],
  "explanationJa": [
    "テストデータは、最終的に出来上がった分類器の性能を評価するためだけに使います。",
    "このとき重要なのは、未知のデータにどれだけうまく対応できるか（＝現実で使えるか）を確認することです。",
    "テスト用のデータが多ければ多いほど、その評価はより正確になります。",
    "一方、データセットが小さいとテスト用データが足りず、現実のデータを自分で手作業で分類（ラベリング）して、評価用データとして使わなければならない場合もあります。"
  ],
  "originalSlideText": "– Testdatensatz: Test der Performanz des finalen und optimierten Klassifizierers\n– Große Datensätze sind hier hilfreich\n– Bei kleinen Datensätzen müssen reale Daten oft händisch klassifiziert werden",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 7,
  "questionDe": "(s5) Wovon hängt die Vorhersage-Performanz ab und welche statistische Grundlage wird zur Bewertung genutzt?",
  "questionJa": "予測性能（Vorhersage-Performanz）は何に依存し、どのような統計的手法が評価に使われるか？",
  "answerDe": [
    "Hängt von der Größe des Testdatensatzes ab",
    "Qualität des Klassifizierers hängt vom Trainingsdatensatz ab",
    "Nutze Statistik: Bernoulli-Kette",
    "– Abfolge von unabhängigen Versuchen",
    "– Beispiel: Münzwurf"
  ],
  "answerJa": [
    "予測性能はテストデータセットの大きさに依存する",
    "分類器の質はトレーニングデータセットに依存する",
    "統計的には「ベルヌーイ列（Bernoulli-Kette）」が使われる",
    "– 独立した試行の連続",
    "– 例：コイン投げ"
  ],
  "explanationDe": [
    "Die Genauigkeit (Performanz) eines Klassifizierers hängt stark davon ab, wie groß der Testdatensatz ist. Je größer dieser ist, desto verlässlicher ist die Einschätzung der Modellgüte.",
    "Gleichzeitig beeinflusst der Trainingsdatensatz die Qualität des Modells – schlechte oder zu wenige Trainingsdaten führen zu einem schlechten Klassifizierer.",
    "Für solche Vorhersageprozesse nutzt man statistische Modelle wie die Bernoulli-Kette. Dabei handelt es sich um eine Reihe von unabhängigen Zufallsversuchen mit genau zwei möglichen Ausgängen (z. B. Erfolg/Misserfolg).",
    "Ein klassisches Beispiel ist der Münzwurf: Jeder Wurf ist unabhängig, und es gibt nur zwei Ausgänge – Kopf oder Zahl."
  ],
  "explanationJa": [
    "分類器の予測性能（どれだけ正確に分類できるか）は、テストデータの量に大きく左右されます。データが多ければ多いほど、モデルの性能を正しく評価できます。",
    "また、分類器自体の質は、どのようなトレーニングデータで学習したかに依存します。不十分なデータでは良い分類器は作れません。",
    "こうした予測の評価には、統計的には「ベルヌーイ列（Bernoulli-Kette）」というモデルが使われます。これは、成功か失敗かという2つの結果しかない独立した試行の繰り返しを表します。",
    "典型的な例がコイン投げです：1回1回の投げは独立していて、結果は「表」か「裏」のどちらかです。"
  ],
  "originalSlideText": "EVALUIERUNG\n\n– Vorhersage Performanz\n\n– Hängt von der Größe des Testdatensatzes ab\n– Qualität des Klassifizierers hängt vom Trainingsdatensatz ab\n– Nutze Statistik: Bernoulli-Kette\n  – Abfolge von unabhängigen Versuchen\n  – Beispiel: Münzwurf",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 8,
  "questionDe": "(s5) Was zeigt das Münzwurf-Beispiel über die Vorhersage und die Erfolgsrate bei einem Bias?",
  "questionJa": "コインに偏り（バイアス）がある場合の予測と成功率の例は何を示しているか？",
  "answerDe": [
    "Angenommen, die Münze hat einen Bias",
    "Führe eine Reihe von Experimenten durch",
    "Sage immer Kopf vorher",
    "Habe eine 75% Erfolgsrate (Vorhersage Kopf, Ergebnis Kopf)",
    "Was ist dann die richtige Erfolgsrate p?"
  ],
  "answerJa": [
    "コインにバイアスがあると仮定する",
    "一連の実験を行う",
    "毎回「表」と予測する",
    "75％の成功率（予測が表、実際も表）を得る",
    "このとき、本当の成功率 p はいくつか？"
  ],
  "explanationDe": [
    "Dieses Beispiel veranschaulicht, wie man bei einem systematischen Bias – also wenn die Münze z. B. häufiger Kopf als Zahl zeigt – die tatsächliche Erfolgswahrscheinlichkeit p schätzen kann.",
    "Man führt viele Versuche durch und macht immer dieselbe Vorhersage (z. B. 'Kopf').",
    "Wenn man bei 75 % der Versuche richtig liegt, deutet das auf eine zugrundeliegende Wahrscheinlichkeit p = 0,75 hin.",
    "Diese Beobachtungen können dann statistisch analysiert werden – etwa mit Methoden aus der Bernoulli-Verteilung –, um abzuschätzen, ob dieser Erfolg zufällig oder systematisch ist."
  ],
  "explanationJa": [
    "このコインの例は、偏り（バイアス）がある状況で、真の成功確率（p）をどのように推定できるかを示しています。",
    "たとえば、常に「表」と予測して実験を何度も繰り返したとき、75％の確率で当たるとすれば、それはコインが75％の確率で表を出すという偏りがある可能性を示唆しています。",
    "このような観測結果は、ベルヌーイ分布のような統計的手法を使って分析することができます。",
    "その結果、観測された成功率が偶然なのか、偏りによるものなのかを評価することができます。"
  ],
  "originalSlideText": "– Angenommen, die Münze hat einen Bias\n  – Führe eine Reihe von Experimenten durch\n  – Sage immer Kopf vorher\n  – Habe eine 75% Erfolgsrate (Vorhersage Kopf, Ergebnis Kopf)\n  – Was ist dann die richtige Erfolgsrate p?",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 9,
  "questionDe": "(s6) Welche Mittelwerte und Varianzen gelten bei einzelnen und mehreren Bernoulli-Versuchen?",
  "questionJa": "単一および複数のベルヌーイ試行における平均（期待値）と分散はどうなるか？",
  "answerDe": [
    "Einzelner Bernoulli Versuch:",
    "– Mittelwert: p",
    "– Varianz: p · (1 − p)",
    "N Bernoulli Versuche:",
    "– Mittelwert: p",
    "– Varianz: p · (1 − p) / N"
  ],
  "answerJa": [
    "1回のベルヌーイ試行：",
    "– 平均（期待値）：p",
    "– 分散：p × (1 − p)",
    "N回のベルヌーイ試行：",
    "– 平均（期待値）：p",
    "– 分散：p × (1 − p) ÷ N"
  ],
  "explanationDe": [
    "Ein Bernoulli-Versuch ist ein Zufallsexperiment mit genau zwei möglichen Ausgängen – z. B. 'Erfolg' (mit Wahrscheinlichkeit p) oder 'Misserfolg' (mit Wahrscheinlichkeit 1−p).",
    "Für einen einzelnen Versuch ist der Erwartungswert (Mittelwert) p, da das Ergebnis 1 (Erfolg) mit p eintritt.",
    "Die Varianz p·(1−p) beschreibt die Streuung der Ergebnisse um diesen Mittelwert.",
    "Wenn man N unabhängige Bernoulli-Versuche durchführt (z. B. 100 Münzwürfe), bleibt der Mittelwert p gleich – aber die Varianz verringert sich auf p·(1−p)/N.",
    "Das bedeutet: Je mehr Versuche man macht, desto stabiler (weniger schwankend) wird das Ergebnis."
  ],
  "explanationJa": [
    "ベルヌーイ試行とは、「成功（確率 p）」または「失敗（確率 1−p）」の2つの結果しかない試行（実験）のことです。たとえばコイン投げが代表例です。",
    "1回の試行では、成功の期待値（平均値）は p になります。たとえば成功確率が0.7なら、平均も0.7です。",
    "分散は p × (1 − p) で表され、結果がどれくらいバラつくか（安定しないか）を示します。",
    "これを N 回繰り返すと、平均値は変わらず p のままですが、分散は小さくなり、p × (1 − p) ÷ N になります。",
    "つまり、試行の回数が増えると、平均のブレが少なくなり、結果が安定してくることを意味します。"
  ],
  "originalSlideText": "EVALUIERUNG\n\n– Vorhersage Performanz\n\n– Einzelner Bernoulli Versuch\n  – Mittelwert: p\n  – Varianz: p · (1 − p)\n\n– N Bernoulli Versuche\n  – Mittelwert: p\n  – Varianz: p·(1−p)/N",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 10,
  "questionDe": "(s6) Wie schaut die Verteilung der Erfolgsraten für große N aus?",
  "questionJa": "試行回数 N が大きいとき、成功率の分布はどのような形になるか？",
  "answerDe": [
    "Wie schaut die Verteilung für große N aus?"
  ],
  "answerJa": [
    "試行回数 N が大きいとき、成功率の分布はどのようになるか？"
  ],
  "explanationDe": [
    "Diese Frage zielt auf das sogenannte Gesetz der großen Zahlen und die Normalverteilung ab.",
    "Wenn N groß wird (viele Bernoulli-Versuche), dann nähert sich die Verteilung der beobachteten Erfolgsrate einer Normalverteilung an.",
    "Das bedeutet: Die Erfolgsraten schwanken weniger, und sie konzentrieren sich immer stärker um den wahren Mittelwert p.",
    "Beispiel: Wenn p = 0.7 ist und man nur 5 Versuche macht, kann die Erfolgsrate stark schwanken (z. B. 40% oder 100%). Bei 1000 Versuchen liegt sie meist sehr nahe bei 70%."
  ],
  "explanationJa": [
    "この問いは、「大数の法則」や「正規分布（ガウス分布）」に関係しています。",
    "試行回数 N が大きくなるにつれて、観測される成功率の分布は正規分布に近づいていきます。",
    "つまり、成功率のばらつきが小さくなり、真の平均（p）の周りに集中するようになります。",
    "たとえば、p = 0.7 のとき、5回しか試行しないと成功率は40%や100%になることもありますが、1000回も試せば多くの場合70%近くに収まります。"
  ],
  "originalSlideText": "– Wie schaut die Verteilung für große N aus?",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 11,
  "questionDe": "(s8) Welche Eigenschaften hat die angenommene Zufallsvariable X bei der Performanzvorhersage?",
  "questionJa": "予測性能に関する評価で仮定される確率変数Xにはどのような性質があるか？",
  "answerDe": [
    "Nimm eine zufällige Variable X an",
    "– Mittelwert: 0",
    "– Varianz: 1",
    "Pr[−z ≤ X ≤ z] = c"
  ],
  "answerJa": [
    "確率変数 X を仮定する",
    "– 平均（期待値）: 0",
    "– 分散: 1",
    "Pr[−z ≦ X ≦ z] = c という形の確率で評価する"
  ],
  "explanationDe": [
    "Um die Performanz einer Vorhersage statistisch zu bewerten, nimmt man häufig eine Zufallsvariable X an, die standardnormalverteilt ist.",
    "Das bedeutet: X hat einen Mittelwert von 0 und eine Varianz von 1 – also eine Normalverteilung mit diesen Standardparametern.",
    "Man interessiert sich für den Bereich, in dem X mit hoher Wahrscheinlichkeit liegt, also z. B. zwischen −z und z.",
    "Der Ausdruck Pr[−z ≤ X ≤ z] = c beschreibt die Wahrscheinlichkeit c, dass X innerhalb dieses Bereichs liegt. Typische Werte für c sind z. B. 0.9 oder 0.95."
  ],
  "explanationJa": [
    "予測の性能を統計的に評価するために、通常は確率変数 X を導入し、X が標準正規分布に従うと仮定します。",
    "標準正規分布とは、平均（期待値）が0、分散が1の正規分布のことです。",
    "このとき、Xが特定の範囲（−zからz）に収まる確率がどれくらいかに注目します。",
    "式 Pr[−z ≦ X ≦ z] = c は、「確率cでXがこの範囲内にある」という意味で、cはたとえば0.9（90%）や0.95（95%）などが使われます。"
  ],
  "originalSlideText": "EVALUIERUNG\n\n– Vorhersage Performanz\n\n– Nimm eine zufällige Variable X an\n  – Mittelwert: 0\n  – Varianz: 1\n– Pr[−z ≤ X ≤ z] = c",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 12,
  "questionDe": "(s8) Wie werden z-Werte und Wahrscheinlichkeiten bei normalverteilten Daten verwendet?",
  "questionJa": "データが正規分布に従うと仮定したとき、z値と確率はどのように使われるか？",
  "answerDe": [
    "Es gibt Tabellen für die Werte z und c",
    "Angenommen, die Daten sind normalverteilt:",
    "– Für einseitige Tests: Pr[X ≥ z]",
    "– Für Normalverteilungen gilt: Pr[X ≥ z] = Pr[X ≤ −z]",
    "– Pr[X ≥ z] = 5% ⇔ X > 1.65 · σ + μ",
    "– Pr[−1.65 ≤ X ≤ 1.65] = 90%",
    "– Finale Gleichung: Pr[−z < (f − p)/√(p·(1−p)/N) < z] = c"
  ],
  "answerJa": [
    "zとcの値には対応表（統計表）がある",
    "データが正規分布に従うと仮定すると：",
    "– 片側検定では Pr[X ≥ z] のように表される",
    "– 正規分布では Pr[X ≥ z] = Pr[X ≤ −z] が成り立つ",
    "– Pr[X ≥ z] = 5% は X > 1.65·σ + μ に相当",
    "– Pr[−1.65 ≦ X ≦ 1.65] = 90%",
    "– 最終的な式：Pr[−z < (f − p)/√(p(1−p)/N) < z] = c"
  ],
  "explanationDe": [
    "Wenn Daten normalverteilt sind, kann man mit z-Werten arbeiten, um Wahrscheinlichkeiten zu berechnen.",
    "z-Werte geben an, wie viele Standardabweichungen ein Wert vom Mittelwert entfernt ist.",
    "Für einseitige Tests interessiert man sich oft für Pr[X ≥ z], d. h. die Wahrscheinlichkeit, dass ein Wert größer als z ist.",
    "Da die Normalverteilung symmetrisch ist, gilt auch Pr[X ≥ z] = Pr[X ≤ −z].",
    "Beispiel: Wenn Pr[X ≥ z] = 5%, dann ist z etwa 1.65. Das bedeutet, nur 5% der Werte liegen oberhalb von μ + 1.65·σ.",
    "Daraus ergibt sich die zentrale Formel: Wenn f eine beobachtete Erfolgsrate ist, dann kann man mit der Formel Pr[−z < (f − p)/√(p·(1−p)/N) < z] = c testen, ob f statistisch im erwarteten Bereich liegt."
  ],
  "explanationJa": [
    "データが正規分布に従うと仮定すると、z値（zスコア）を使って確率を求めることができます。",
    "z値は「平均から何標準偏差離れているか」を示す指標です。",
    "片側検定では、ある値がz以上である確率 Pr[X ≧ z] を求めることが多く、これは「極端な値が出る確率」として解釈されます。",
    "正規分布は左右対称なので、Pr[X ≧ z] = Pr[X ≦ −z] という関係も成り立ちます。",
    "たとえば Pr[X ≧ z] = 5% の場合、z ≈ 1.65 となり、Xが μ + 1.65·σ を超える確率が5%であることを意味します。",
    "この考えを使って、観測された成功率 f が期待値 p の近くにあるかどうかを、次のような式で評価します：",
    "Pr[−z < (f − p)/√(p(1−p)/N) < z] = c"
  ],
  "originalSlideText": "– Es gibt Tabellen für die Werte z und c\n\n– Angenommen, die Daten sind normalverteilt:\n  – Für einseitige Tests sehen die Tabellen so aus : Pr[X ≥ z]\n  – Für Normalverteilungen gilt: Pr[X ≥ z] = Pr[X ≤ −z]\n  – Pr[X ≥ z] = 5%: 5% Chance, dass X > 1.65 · σ + μ\n  – Äquivalent zu: Pr[−1.65 ≤ X ≤ 1.65] = 90%\n  – Finale Gleichung: Pr[−z < (f − p)/√(p·(1−p)/N) < z] = c",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 13,
  "questionDe": "(s9) Wie kann man Konfidenzgrenzen für die Vorhersageperformanz berechnen?",
  "questionJa": "予測性能の信頼区間（Konfidenzgrenzen）はどのように計算するのか？",
  "answerDe": [
    "Konfidenzgrenzen:",
    "p = (f + z²/(2N) ± z · √[(f/N)·(1−f) + z²/(4N²)]) / (1 + z²/N)",
    "Erhalte von c (Konfidenz) z aus der Tabelle",
    "Nutze die Formel mit:",
    "– Erfolgsrate f = S / N",
    "– S: Anzahl der Erfolge",
    "– N: Anzahl der Versuche",
    "– z: siehe Tabelle"
  ],
  "answerJa": [
    "信頼区間（Konfidenzgrenzen）の式：",
    "p = (f + z²/(2N) ± z × √[(f/N)(1−f) + z²/(4N²)]) ÷ (1 + z²/N)",
    "信頼度cからz値を統計表で得る",
    "以下の値を使って計算：",
    "– 成功率 f = S ÷ N",
    "– S：成功の回数",
    "– N：試行回数",
    "– z：統計表を参照"
  ],
  "explanationDe": [
    "Die Formel dient dazu, eine Konfidenzgrenze (Vertrauensintervall) für die wahre Erfolgswahrscheinlichkeit p anzugeben – basierend auf beobachteter Erfolgsrate f.",
    "Man berücksichtigt dabei die Unsicherheit durch die Anzahl der Versuche N sowie das gewünschte Konfidenzniveau c, das über den z-Wert aus einer Tabelle bestimmt wird.",
    "Die Erfolgsrate f ergibt sich als Anteil der Erfolge (S) an der Gesamtzahl der Versuche (N), also f = S / N.",
    "Die ± Komponente gibt an, dass man einen unteren und oberen Bereich angibt, zwischen dem der wahre Wert p mit hoher Wahrscheinlichkeit liegt.",
    "Beispiel: Bei 100 Versuchen (N=100), 75 Erfolgen (S=75), f=0.75, z=1.96 für 95% Konfidenz – damit kann man p mit dieser Formel berechnen."
  ],
  "explanationJa": [
    "この式は、観測された成功率 f に基づいて、本当の成功確率 p がどの範囲にあるか（信頼区間）を求めるためのものです。",
    "試行回数 N が少ないと結果にばらつきが出るため、統計的な「誤差の幅」を考慮して、上下の範囲を計算します。",
    "信頼度（たとえば90％や95％）に応じて z 値（標準正規分布の臨界値）を統計表から調べ、それを式に代入して計算します。",
    "成功率 f は、成功数 S を試行数 N で割った値です（f = S ÷ N）。",
    "±の部分は、p の推定値の上下にどのくらいの幅があるかを示します。",
    "例：試行数N=100、成功数S=75ならf=0.75、信頼度95%ではz=1.96を使い、この式でpの信頼区間を求めることができます。"
  ],
  "originalSlideText": "EVALUIERUNG\n\n– Vorhersage Performanz\n\n– Konfidenzgrenzen:\n  – p = (f + z² / 2N ± z √[f/N · (1 − f) + z² / 4N²]) / (1 + z² / N)\n\n– Erhalte von c (Konfidenz) z aus der Tabelle\n\n– Nutze die Formel mit:\n  – Erfolgsrate f = S / N\n  – S: Anzahl der Erfolge\n  – N: Anzahl der Versuche\n  – z: siehe Tabelle",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 14,
  "questionDe": "(s10) Wie beeinflusst die Anzahl der Versuche N die Breite des Konfidenzintervalls?",
  "questionJa": "試行回数 N の大きさは信頼区間の幅にどのような影響を与えるか？",
  "answerDe": [
    "f = 75%, N = 1000, c = 80% ergibt [0.732, 0.767]",
    "f = 75%, N = 100, c = 80% ergibt [0.691, 0.801]"
  ],
  "answerJa": [
    "f = 75%、N = 1000、c = 80% → 信頼区間 [0.732, 0.767]",
    "f = 75%、N = 100、c = 80% → 信頼区間 [0.691, 0.801]"
  ],
  "explanationDe": [
    "Diese beiden Beispiele zeigen, dass mit zunehmender Anzahl an Versuchen (N) die Konfidenzintervalle enger werden.",
    "Bei N = 1000 ist das Intervall [0.732, 0.767] – also sehr schmal, was auf eine präzisere Schätzung hinweist.",
    "Bei N = 100 ist das Intervall [0.691, 0.801] – deutlich breiter, also mit größerer Unsicherheit.",
    "Je größer N ist, desto sicherer kann man die wahre Erfolgswahrscheinlichkeit eingrenzen."
  ],
  "explanationJa": [
    "この例は、試行回数 N が多くなるほど、信頼区間の幅が狭くなり、予測がより精密になることを示しています。",
    "N = 1000 のときの信頼区間は [0.732, 0.767] で、かなり狭くなっています。つまり成功率の推定に対する信頼性が高いということです。",
    "一方、N = 100 の場合、区間は [0.691, 0.801] と広くなっており、不確実性が大きくなります。",
    "このように、N が大きいほど予測の精度と信頼性が高まるのです。"
  ],
  "originalSlideText": "EVALUIERUNG\n\n– Vorhersage Performanz\n  – f = 75%, N = 1000, c = 80% ergibt [0.732, 0.767]\n  – f = 75%, N = 100, c = 80% ergibt [0.691, 0.801]",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 15,
  "questionDe": "(s10) Wann ist die Annahme einer Normalverteilung bei der Evaluation sinnvoll?",
  "questionJa": "Evaluationにおいて正規分布の仮定が有効なのはどんな場合か？",
  "answerDe": [
    "Die Annahme einer Normalverteilung ist nur bei großen N schlüssig!"
  ],
  "answerJa": [
    "正規分布の仮定が妥当なのは、N（試行回数）が大きい場合に限られる"
  ],
  "explanationDe": [
    "Die Normalverteilung wird in der Statistik oft verwendet, um Wahrscheinlichkeiten zu modellieren.",
    "Allerdings setzt sie voraus, dass genügend viele Datenpunkte vorhanden sind – also ein großer Stichprobenumfang (großes N).",
    "Bei kleinen N kann die tatsächliche Verteilung der Daten deutlich von der Normalverteilung abweichen, was zu falschen Schlüssen führen kann.",
    "Deshalb gilt: Nur bei großen N sind Annahmen über Normalverteilung für Konfidenzintervalle und Hypothesentests sinnvoll."
  ],
  "explanationJa": [
    "統計では正規分布を仮定してさまざまな分析を行いますが、この仮定が成り立つのはデータ数（試行回数N）が十分に多い場合に限られます。",
    "N が小さい場合、データの分布は正規分布とは異なる可能性が高く、正規分布を前提とした計算結果は信頼できなくなります。",
    "したがって、信頼区間の計算や仮説検定などで正規分布を前提にするのは、N が大きいときに限るべきです。"
  ],
  "originalSlideText": "– Erinnerung:\n  – Die Annahme einer Normalverteilung ist nur bei großen N schlüssig!",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 16,
  "questionDe": "(Klausur) Wie werden Trainings- und Testdaten in der Evaluierung genutzt und wie läuft der Evaluierungsprozess allgemein ab?",
  "questionJa": "（試験）評価（Evaluation）において、トレーニングデータとテストデータはどのように使われるか？評価プロセス全体の流れは？",
  "answerDe": [
    "Trainingsdaten dienen zur Erstellung und Anpassung des Modells",
    "Testdaten werden verwendet, um die Vorhersagequalität des fertigen Modells zu überprüfen",
    "Evaluation erfolgt typischerweise durch Vergleich der Fehlerrate auf neuen, nicht gesehenen Daten",
    "Daten werden in Trainings- und Testdatensatz aufgeteilt (z. B. Holdout, Kreuzvalidierung)",
    "Ergebnisse mehrerer Testläufe werden oft gemittelt, um stabile Aussagen zu treffen"
  ],
  "answerJa": [
    "トレーニングデータはモデルの構築・調整に使われる",
    "テストデータは、最終的なモデルの予測性能を評価するために使われる",
    "評価は通常、未知の新しいデータに対する誤分類率を比較して行われる",
    "データはトレーニング用とテスト用に分割される（例：ホールドアウト法、交差検証）",
    "複数のテスト結果を平均することで、より信頼できる評価が得られる"
  ],
  "explanationDe": [
    "Der Evaluierungsprozess beginnt mit dem Aufteilen der verfügbaren Daten in zwei (oder mehr) Gruppen: Trainingsdaten und Testdaten.",
    "Die Trainingsdaten werden verwendet, um das Modell zu trainieren – das bedeutet, dass es aus diesen Daten die zugrundeliegenden Muster lernt.",
    "Die Testdaten hingegen werden beiseitegelegt und erst nach dem Training verwendet, um zu prüfen, wie gut das Modell auf neue, unbekannte Daten reagiert.",
    "Dadurch kann man feststellen, ob das Modell nur 'auswendig gelernt' hat (Overfitting) oder tatsächlich generalisieren kann.",
    "Typische Methoden zur Evaluierung sind: Holdout-Methode, bei der man einen Teil der Daten zum Testen reserviert, und Kreuzvalidierung, bei der alle Daten abwechselnd zum Testen verwendet werden.",
    "Um faire Ergebnisse zu bekommen, wiederholt man den Prozess oft mehrfach (z. B. Repeated Holdout oder K-fold-Crossvalidation) und bildet den Durchschnitt der Fehlerraten."
  ],
  "explanationJa": [
    "評価のプロセスは、利用可能なデータをトレーニング用（学習用）とテスト用（評価用）に分けることから始まります。",
    "トレーニングデータは、モデルがパターンや規則を学習するために使われます。つまり、分類や予測のルールを見つける材料になります。",
    "一方、テストデータは学習には使わず、学習が終わった後にモデルの性能をチェックするために用います。",
    "これにより、モデルが単にデータを暗記しただけなのか、それとも未知のデータにも対応できるのか（汎化能力があるか）を確認できます。",
    "評価手法としては、事前にテスト用データを取り置くホールドアウト法や、全体のデータを均等に分けて順番にテストに使う交差検証（クロスバリデーション）などがあります。",
    "信頼性を高めるために、評価を何回か繰り返して（例：繰り返しホールドアウトやk分割交差検証）、それぞれの誤差率を平均して最終的な評価とするのが一般的です。"
  ],
  "originalSlideText": "Zusammenfassung aus mehreren Folien:\n– Trainingsdaten: Modell lernen\n– Testdaten: Modell testen (nicht gesehen)\n– Bewertung mit Fehlerrate\n– Methoden: Holdout, Stratifikation, Repeated Holdout, Kreuzvalidierung\n– Ziel: Generalisierbarkeit des Modells auf neue Daten prüfen",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 17,
  "questionDe": "(s11) Was ist die Holdout-Methode und wie wird sie angewendet?",
  "questionJa": "ホールドアウト法（Holdout-Methode）とは何か？ どのように使われるのか？",
  "answerDe": [
    "Holdout Methode",
    "– Datenmengen für das Lernen und Testen sind oft limitiert verfügbar",
    "– Reserviere vorab einen Teil der Daten für das Testen",
    "– Nutzung der restlichen Daten für das Training"
  ],
  "answerJa": [
    "ホールドアウト法（Holdout Methode）",
    "– 学習やテストに使えるデータ量は限られていることが多い",
    "– 事前にデータの一部をテスト用に確保する",
    "– 残りのデータを学習（トレーニング）に使用する"
  ],
  "explanationDe": [
    "Die Holdout-Methode ist ein einfaches Verfahren zur Evaluation von Modellen.",
    "Dabei teilt man die verfügbaren Daten in zwei getrennte Mengen auf: eine für das Training (Lernen des Modells) und eine für das Testen (Überprüfung der Vorhersagequalität).",
    "Da oft nicht unbegrenzt viele Daten zur Verfügung stehen, ist es wichtig, effizient mit der Aufteilung umzugehen.",
    "Der Testdatensatz wird dabei nicht zum Lernen verwendet, sondern erst am Ende zur Bewertung des Modells."
  ],
  "explanationJa": [
    "ホールドアウト法とは、モデルの性能を評価するために用いられる基本的な方法です。",
    "持っているデータを2つに分け、一方を学習（トレーニング）用、もう一方を評価（テスト）用に使います。",
    "多くの場合、使えるデータは限られているため、最初に一部のデータをテスト用として「取り置き」しておくのがポイントです。",
    "このテスト用データは学習には使わず、モデルが完成した後でその性能を確認するために使います。"
  ],
  "originalSlideText": "EVALUIERUNG\n\n– Holdout Methode\n\n– Datenmengen für das Lernen und Testen sind oft limitiert verfügbar\n– Reserviere vorab einen Teil der Daten für das Testen\n– Nutzung der restlichen Daten für das Training",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 18,
  "questionDe": "(s11) Wie wird die Datenaufteilung bei der Holdout-Methode typischerweise vorgenommen?",
  "questionJa": "ホールドアウト法では、データはどのように分割されるのが一般的か？",
  "answerDe": [
    "Manchmal müssen auch Daten für die Validierung reserviert werden",
    "Oft:",
    "– Ein Drittel für das Testen",
    "– Zwei Drittel für das Training"
  ],
  "answerJa": [
    "検証（バリデーション）用にもデータを確保することがある",
    "一般的には：",
    "– 3分の1をテスト用に使う",
    "– 3分の2を学習（トレーニング）用に使う"
  ],
  "explanationDe": [
    "Je nach Anwendungsfall kann es sinnvoll sein, die Daten nicht nur in Trainings- und Testdaten zu unterteilen, sondern auch einen Validierungssatz zu nutzen.",
    "Ein typisches Aufteilungsverhältnis bei der Holdout-Methode ist: 2/3 der Daten für das Training, 1/3 für das Testen.",
    "Diese Aufteilung bietet einen guten Kompromiss zwischen ausreichendem Lernmaterial und zuverlässiger Evaluation.",
    "Bei noch komplexeren Modellen kann zusätzlich ein Validierungssatz nötig sein, um Parameter während des Trainings zu optimieren."
  ],
  "explanationJa": [
    "状況によっては、テスト用だけでなく、検証用（バリデーション）のデータも分けておく必要があります。",
    "ホールドアウト法では、典型的には次のようにデータを分けます：トレーニング用に全体の3分の2、テスト用に3分の1。",
    "このような分割は、モデルの学習に十分なデータを使いながら、信頼性のある評価も行える、バランスの取れた方法です。",
    "さらに複雑なモデルでは、ハイパーパラメータの調整などにバリデーションデータが必要になることもあります。"
  ],
  "originalSlideText": "– Manchmal müssen auch Daten für die Validierung reserviert werden\n– Oft:\n  – Ein Drittel für das Testen\n  – Zwei Drittel für das Training",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 19,
  "questionDe": "(s12) Welches Problem kann bei der Holdout-Methode bezüglich der Repräsentativität der Daten auftreten?",
  "questionJa": "ホールドアウト法では、データの代表性に関してどんな問題が発生するか？",
  "answerDe": [
    "Problem: Die Datensätze können nicht repräsentativ sein",
    "– Im Trainingsdatensatz fehlt eine Klasse",
    "– Eine Klasse ist im Trainingsdatensatz unterrepräsentiert"
  ],
  "answerJa": [
    "問題：データセットが代表的でない可能性がある",
    "– トレーニングデータにあるクラスが全く含まれない",
    "– 特定のクラスがトレーニングデータ内で非常に少ない"
  ],
  "explanationDe": [
    "Ein wesentliches Problem bei der Holdout-Methode ist, dass die zufällige Aufteilung der Daten zu ungleichen Klassenverteilungen führen kann.",
    "Zum Beispiel könnte es passieren, dass eine Klasse (z. B. 'Krank' oder 'Spam') im Trainingsdatensatz komplett fehlt oder sehr selten vertreten ist.",
    "Das bedeutet, dass das Modell nicht richtig lernen kann, diese Klasse zu erkennen, weil es dafür keine oder zu wenige Beispiele gibt.",
    "Solche Verteilungen führen zu schlechten Vorhersagen und verzerren die Evaluation."
  ],
  "explanationJa": [
    "ホールドアウト法では、データをランダムに分割することで、各クラスの分布が偏ってしまうことがあります。",
    "例えば「スパム」などのあるクラスが、トレーニングデータに全く含まれなかったり、非常に少なかったりすると、モデルはそのクラスを正しく学習できません。",
    "このような不均衡は、モデルの性能を下げたり、評価結果を誤解させたりする原因になります。",
    "そのため、クラスの分布が代表的であることが重要になります。"
  ],
  "originalSlideText": "EVALUIERUNG\n\n– Holdout Methode\n\n– Problem: Die Datensätze können nicht repräsentativ sein\n  – Im Trainingsdatensatz fehlt eine Klasse\n  – Eine Klasse ist im Trainingsdatensatz unterrepräsentiert",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 20,
  "questionDe": "(s12) Wie kann man das Repräsentativitätsproblem bei der Holdout-Methode lösen?",
  "questionJa": "ホールドアウト法での代表性の問題をどのように解決できるか？",
  "answerDe": [
    "Lösung: Stratifikation",
    "– Random sampling",
    "– Garantiere, dass jede Klasse in Trainingsdatensatz und Testdatensatz gleich repräsentiert ist",
    "– Methode: Stratified Holdout",
    "– Ist nur eine simple Absicherung gegen ungleiche Verteilungen"
  ],
  "answerJa": [
    "解決策：Stratifikation（層化）",
    "– ランダムサンプリングを行う",
    "– 各クラスが学習・テストデータに同じように含まれるようにする",
    "– 方法：Stratified Holdout（層化ホールドアウト）",
    "– 不均一な分布を避けるための簡易的な対策である"
  ],
  "explanationDe": [
    "Um das Problem ungleich verteilter Klassen in Trainings- und Testdaten zu vermeiden, verwendet man eine Technik namens Stratifikation.",
    "Dabei wird sichergestellt, dass jede Klasse (z. B. 'Ja' und 'Nein') in beiden Datensätzen proportional vertreten ist.",
    "Dies geschieht durch sogenanntes 'stratifiziertes Sampling' – gezielte Zufallsauswahl mit Berücksichtigung der Klassenverteilung.",
    "Die Methode nennt sich Stratified Holdout und ist eine einfache, aber effektive Maßnahme gegen unrepräsentative Datenaufteilungen."
  ],
  "explanationJa": [
    "クラスの分布が偏る問題を避けるために、『Stratifikation（層化）』という方法が用いられます。",
    "これは、各クラスが学習データとテストデータに同じ割合で含まれるようにデータを分ける手法です。",
    "ランダムにデータを選ぶ際に、クラスごとに分けてから抽出することで、クラスの偏りを防ぎます。",
    "この方法は『Stratified Holdout（層化ホールドアウト）』と呼ばれ、簡単ですが効果的な対策です。"
  ],
  "originalSlideText": "– Lösung: Stratifikation\n\n– Random sampling\n– Garantiere, dass jede Klasse in Trainingsdatensatz und Testdatensatz gleich repräsentiert ist\n– Methode: Stratified Holdout\n– Ist nur eine simple Absicherung gegen ungleiche Verteilungen",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 21,
  "questionDe": "(s13) Was ist die Repeated Holdout Methode und wie funktioniert sie?",
  "questionJa": "Repeated Holdout（繰り返しホールドアウト）法とは何か？どのように行うのか？",
  "answerDe": [
    "Repeated Holdout",
    "– Wiederhole die Analyse (mit Stratifikation) mehrere Male",
    "– Wähle jedes Mal eine Teilmenge der Daten zufällig für das Testen",
    "– Nutze die restlichen Daten als Trainingsdatensatz"
  ],
  "answerJa": [
    "Repeated Holdout（繰り返しホールドアウト）",
    "– ストラティフィケーション付きの分析を複数回繰り返す",
    "– 毎回テスト用にデータの一部をランダムに選ぶ",
    "– 残りのデータをトレーニング用に使う"
  ],
  "explanationDe": [
    "Bei der Repeated Holdout Methode wird die einfache Holdout-Analyse mehrfach durchgeführt, typischerweise mit zufälligen und ggf. stratifizierten Stichproben.",
    "In jedem Durchlauf wird ein neuer Testdatensatz zufällig ausgewählt, der Rest dient zum Training.",
    "Diese Wiederholung erlaubt eine robustere Einschätzung der Modellqualität, da verschiedene Teilmengen betrachtet werden.",
    "Insbesondere bei kleinen Datensätzen kann dies helfen, die Abhängigkeit vom Zufall zu reduzieren."
  ],
  "explanationJa": [
    "Repeated Holdout（繰り返しホールドアウト）法とは、ホールドアウト法を複数回繰り返してモデルの性能をより安定的に評価する方法です。",
    "各回でテスト用のデータをランダムに選び、残りを学習用に使います。必要であれば層化（Stratifikation）も取り入れます。",
    "これにより、評価が特定の分割に依存するリスクを減らし、全体としてのモデルの信頼性を高めることができます。",
    "特にデータ量が少ない場合に有効で、偶然の影響を減らせます。"
  ],
  "originalSlideText": "EVALUIERUNG\n\n– Repeated Holdout\n\n– Wiederhole die Analyse (mit Stratifikation) mehrere Male\n– Wähle jedes Mal eine Teilmenge der Daten zufällig für das Testen\n– Nutze die restlichen Daten als Trainingsdatensatz",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 22,
  "questionDe": "(s13) Wie wird die zusammengefasste Fehlerrate bei Repeated Holdout berechnet?",
  "questionJa": "Repeated Holdout で得られた誤差率はどのようにまとめて評価するのか？",
  "answerDe": [
    "Zusammengefasste Fehlerrate:",
    "– Bilde den Durchschnitt über alle einzelnen Fehlerraten"
  ],
  "answerJa": [
    "まとめた誤差率（Fehlerrate）：",
    "– 各回の誤差率の平均を取る"
  ],
  "explanationDe": [
    "Da bei Repeated Holdout viele einzelne Tests durchgeführt werden, erhält man auch viele verschiedene Fehlerraten.",
    "Um daraus eine Gesamtaussage zu treffen, berechnet man den Durchschnitt aller Fehlerraten.",
    "Dieser Mittelwert ist dann die zusammengefasste Fehlerrate und dient als stabile Einschätzung der Modellgüte über mehrere Datenaufteilungen hinweg."
  ],
  "explanationJa": [
    "Repeated Holdout では、何度もテストと学習を繰り返すため、誤差率もその回ごとに異なる値になります。",
    "それらの誤差率をすべて集めて平均を取ることで、全体としての安定した評価が得られます。",
    "この平均値が「まとめた誤差率」となり、さまざまなデータの分割パターンを考慮した上でのモデルの総合的な性能を示します。"
  ],
  "originalSlideText": "– Zusammengefasste Fehlerrate:\n  – Bilde den Durchschnitt über alle einzelnen Fehlerraten",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 23,
  "questionDe": "(s14) Was ist Kreuzvalidierung und wie wird sie durchgeführt?",
  "questionJa": "交差検証（Kreuzvalidierung）とは何か？どのように行うのか？",
  "answerDe": [
    "Kreuzvalidierung",
    "– Erweiterung der holdout Methode",
    "– Wähle eine feste Anzahl an folds (Partitionen) für die Daten",
    "– Normalerweise sind alle folds gleich groß",
    "– Jedes fold wird für das Testen genutzt",
    "– Die übrigen werden für das Training genutzt"
  ],
  "answerJa": [
    "交差検証（Kreuzvalidierung）",
    "– ホールドアウト法を拡張した手法",
    "– データをfold（分割）数に固定して分ける",
    "– 通常、すべてのfoldは同じサイズ",
    "– 各foldを1回ずつテスト用に使う",
    "– 残りのfoldを学習用に使う"
  ],
  "explanationDe": [
    "Kreuzvalidierung ist eine Evaluierungsmethode, bei der die Daten in mehrere gleich große Teile (folds) aufgeteilt werden.",
    "Bei jedem Durchgang wird ein anderer fold als Testdatensatz verwendet, während die restlichen folds zum Trainieren des Modells genutzt werden.",
    "Dieser Prozess wird so oft wiederholt, wie es folds gibt – bei 5 folds also 5-mal.",
    "Kreuzvalidierung ist eine Erweiterung der Holdout-Methode, die eine stabilere und weniger zufallsabhängige Schätzung der Modellqualität erlaubt."
  ],
  "explanationJa": [
    "交差検証（クロスバリデーション）は、データをいくつかのfold（区切り、分割）に分けて行うモデル評価手法です。",
    "1つのfoldをテスト用に、残りのfoldを学習用に使い、これをfoldの数だけ繰り返します（例：5分割なら5回）。",
    "この方法は、ホールドアウト法を改良したもので、ランダムな分割に依存せず、より安定した評価結果が得られます。",
    "通常、すべてのfoldは同じサイズで、公平な比較ができるようにします。"
  ],
  "originalSlideText": "EVALUIERUNG\n\n– Kreuzvalidierung\n– Erweiterung der holdout Methode\n– Wähle eine feste Anzahl an folds (Partitionen) für die Daten\n– Normalerweise sind alle folds gleich groß\n– Jedes fold wird für das Testen genutzt\n– Die übrigen werden für das Training genutzt",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 24,
  "questionDe": "(s14) Wie bewertet man die Leistung bei Kreuzvalidierung und was bedeutet 'dreifache Kreuzvalidierung'?",
  "questionJa": "交差検証における性能評価はどのように行われるか？また「3分割交差検証」とは何か？",
  "answerDe": [
    "Bei drei folds:",
    "– Dreifache Kreuzvalidierung",
    "– Stratifizierte dreifache Kreuzvalidierung",
    "– Bilde den Durchschnitt der Fehlerraten"
  ],
  "answerJa": [
    "fold数が3の場合：",
    "– 3分割交差検証（Dreifache Kreuzvalidierung）",
    "– 層化された3分割交差検証（Stratifizierte dreifache Kreuzvalidierung）",
    "– 各foldで得られた誤差率の平均を取る"
  ],
  "explanationDe": [
    "Bei dreifacher Kreuzvalidierung wird der Datensatz in drei gleich große Teile geteilt.",
    "Jeder Teil wird einmal zum Testen und zweimal zum Trainieren verwendet.",
    "Wenn man sicherstellen möchte, dass die Klassenverteilung in allen drei Teilen gleich ist, spricht man von stratifizierter dreifacher Kreuzvalidierung.",
    "Zur Gesamtbewertung berechnet man den Durchschnitt der drei einzelnen Fehlerraten – das ergibt eine robustere Leistungskennzahl."
  ],
  "explanationJa": [
    "3分割交差検証とは、データを3等分して、各部分を1回ずつテスト用に使う手法です。",
    "つまり3回の学習・評価を行い、それぞれの誤差率を計算します。",
    "さらに、各foldにおいてクラスの分布が偏らないようにする場合は「層化3分割交差検証」と呼ばれます。",
    "最後に、各foldで得られた誤差率の平均を取り、モデルの総合的な性能を評価します。"
  ],
  "originalSlideText": "– Bei drei folds:\n  – Dreifache Kreuzvalidierung\n  – Stratifizierte dreifache Kreuzvalidierung\n– Bilde den Durchschnitt der Fehlerraten",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 25,
  "questionDe": "(s15) Warum wird bei der Kreuzvalidierung häufig 10-fold verwendet?",
  "questionJa": "交差検証ではなぜよく10分割（10-fold）が使われるのか？",
  "answerDe": [
    "Standard: 10 folds",
    "Warum 10?",
    "– Praktische Erfahrungen",
    "– Theoretische Nachweise",
    "– Muss dennoch nicht als „Standardwert“ angenommen werden!"
  ],
  "answerJa": [
    "標準：10分割（10-fold）",
    "なぜ10なのか？",
    "– 実践的な経験に基づく",
    "– 理論的な裏付けもある",
    "– それでも「標準値」として盲目的に使う必要はない"
  ],
  "explanationDe": [
    "In der Praxis hat sich 10-fold Kreuzvalidierung als ein guter Kompromiss zwischen Aufwand und Genauigkeit erwiesen.",
    "Sie bietet stabile Schätzungen der Modellgüte, ohne zu viel Rechenzeit zu erfordern.",
    "Auch theoretische Studien belegen, dass 10 Folds oft zu guten Resultaten führen.",
    "Aber: Je nach Anwendungsfall, Datensatzgröße oder Ziel kann eine andere Anzahl an Folds sinnvoller sein (z. B. 5, 20 oder Leave-One-Out).",
    "Deshalb sollte 10-fold nicht blind als Standard übernommen werden – es ist ein bewährter Richtwert, aber kein Muss."
  ],
  "explanationJa": [
    "実務の現場では、10分割交差検証（10-fold cross validation）は「精度」と「計算コスト」のバランスがよく、多くの場面で有効とされています。",
    "また、理論的にも10分割が妥当な評価を得られることが研究で示されています。",
    "しかし、それが必ずしもすべてのケースに最適とは限りません。データ量が少ない場合はより少ないfold数、またはLeave-One-Outのような方法のほうが適していることもあります。",
    "したがって、10-foldは『経験的に良い』という目安に過ぎず、常に正解というわけではないという点に注意が必要です。"
  ],
  "originalSlideText": "EVALUIERUNG\n\n– Kreuzvalidierung\n\n– Standard: 10 folds\n– Warum 10?\n  – Praktische Erfahrungen\n  – Theoretische Nachweise\n  – Muss dennoch nicht als “Standardwert” angenommen werden!",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 26,
  "questionDe": "(Klausur) Erklären Sie das Prinzip der K-Fold Kreuzvalidierung. Welche Anzahl an Folds wird häufig verwendet und warum?",
  "questionJa": "（試験）K-Fold交差検証の仕組みを説明せよ。また、一般的によく使われるfold数とその理由について述べよ。",
  "answerDe": [
    "Kreuzvalidierung: Erweiterung der Holdout-Methode",
    "Daten werden in k gleich große Folds (Teilmengen) aufgeteilt",
    "Jeder Fold wird einmal als Testdatensatz verwendet, die übrigen als Trainingsdatensatz",
    "Standard ist oft 10 Folds",
    "Begründung: Praktische Erfahrungen und theoretische Nachweise"
  ],
  "answerJa": [
    "交差検証：ホールドアウト法の拡張",
    "データをk個の等しいfold（部分集合）に分ける",
    "各foldを1回ずつテスト用に使い、残りを学習用にする",
    "一般的には10分割（10-fold）がよく使われる",
    "理由：実務的な経験と理論的な裏付けがあるため"
  ],
  "explanationDe": [
    "Bei der K-Fold Kreuzvalidierung wird der gesamte Datensatz in k gleich große Teile (folds) unterteilt.",
    "In jedem der k Durchläufe wird ein anderer Fold als Testdatensatz verwendet, während die restlichen k−1 Folds dem Training dienen.",
    "Am Ende berechnet man den Durchschnitt der k Fehlerwerte, um eine stabile Gesamteinschätzung zu erhalten.",
    "Die Methode reduziert Zufallseinflüsse im Vergleich zum einfachen Holdout.",
    "Typischerweise wird k = 10 gewählt, da sich dies in der Praxis bewährt hat und auch theoretisch gute Ergebnisse liefert.",
    "Allerdings ist 10 kein Muss – je nach Datensatzgröße und Problemstellung kann auch eine andere Zahl sinnvoll sein."
  ],
  "explanationJa": [
    "K-Fold交差検証では、データセット全体をk個の等しいfold（区切り、分割）に分けます。",
    "k回の実験を行い、毎回1つのfoldをテスト用に使い、残りk−1個を学習用にします。",
    "その後、それぞれの誤差率を平均して、モデルの総合的な性能を評価します。",
    "これは、1回だけの分割に頼るホールドアウト法よりも、より安定した評価を得ることができます。",
    "一般的にはk=10がよく使われます（10-fold）。これは実務でも多くの成功例があり、また理論的にも良好な性能が得られることが確認されています。",
    "ただし、必ずしも10が最適とは限らず、データ量や問題の性質によっては別の値を使うこともあります。"
  ],
  "originalSlideText": "– Kreuzvalidierung\n– Wähle eine feste Anzahl an folds\n– Jedes fold wird für das Testen genutzt\n– Die übrigen für das Training\n– Standard: 10 folds\n– Praktische Erfahrungen\n– Theoretische Nachweise\n– Muss dennoch nicht als “Standardwert” angenommen werden!",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 27,
  "questionDe": "(s16) Was ist Leave-one-out Kreuzvalidierung und wie funktioniert sie?",
  "questionJa": "Leave-one-out交差検証（LOOCV）とは何か？どのように行われるか？",
  "answerDe": [
    "Datensatz mit n Instanzen",
    "Führe n-fache Kreuzvalidierung durch",
    "Lasse jede Instanz einmal aus",
    "Nutze n−1 Instanzen für das Training",
    "Nutze 1 Instanz für das Testen",
    "Bilde den Durchschnitt aller n Bewertungen"
  ],
  "answerJa": [
    "n個のインスタンス（データ）があるとする",
    "n回の交差検証を行う",
    "各回で1つのインスタンスを除外する",
    "残りn−1個を学習に使う",
    "除外した1つをテストに使う",
    "すべての評価結果の平均をとる"
  ],
  "explanationDe": [
    "Die Leave-one-out Kreuzvalidierung (LOOCV) ist eine spezielle Form der Kreuzvalidierung, bei der jede einzelne Instanz im Datensatz einmal als Testdaten verwendet wird.",
    "Angenommen, der Datensatz enthält n Instanzen: Dann führt man n Durchläufe durch.",
    "In jedem Durchlauf wird genau eine Instanz zum Testen verwendet, und die restlichen n−1 Instanzen werden zum Trainieren des Modells genutzt.",
    "Das Modell wird also n-mal trainiert und getestet – einmal pro Instanz.",
    "Am Ende berechnet man den Durchschnitt aller n Fehlerraten, um eine Gesamtbewertung zu erhalten.",
    "Vorteil: Maximale Nutzung der Daten, besonders bei kleinen Datensätzen. Nachteil: Sehr rechenintensiv bei großen n."
  ],
  "explanationJa": [
    "Leave-one-out交差検証（LOOCV）は、交差検証の一種で、データセットの各インスタンスを1回ずつテスト用に使う方法です。",
    "たとえばデータがn個あるとすると、n回の検証を行い、そのたびに1つだけデータをテスト用に取り出し、残りのn−1個でモデルを学習させます。",
    "これをn回繰り返すことで、すべてのデータが一度ずつテストに使われることになります。",
    "最後に、それぞれのテスト結果（誤差率など）を平均して、全体の性能を評価します。",
    "メリットは、データを最大限活用できること（特に小さなデータセットでは有効）。",
    "デメリットは、データが多い場合に非常に時間と計算コストがかかる点です。"
  ],
  "originalSlideText": "EVALUIERUNG\n\n– Leave-one-out Kreuzvalidierung\n– Datensatz: n Instanzen\n– n-fold Kreuzvalidierungen\n  – Lasse jede Instanz nacheinander aus\n  – Nutze n−1 Instanzen für das Training\n  – Nutze eine Instanz für das Testen\n  – Bilde den Durchschnitt über alle n Bewertungen",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 28,
  "questionDe": "(s17)  Nennen Sie vier Vorteile der Leave-one-out Kreuzvalidierung.",
  "questionJa": "Leave-one-out交差検証（LOOCV）の利点を4つ挙げよ。",
  "answerDe": [
    "Nutzung der maximal möglichen Datenmenge für das Training",
    "Kann zur Steigerung der Klassifikatorleistung führen",
    "Deterministisch – kein zufälliges Sampling nötig",
    "Optimal für kleinere Datensätze geeignet"
  ],
  "answerJa": [
    "学習に利用できるデータ量を最大限活用できる",
    "分類器の性能が向上する可能性がある",
    "決定的な手法であり、ランダムサンプリングを必要としない",
    "小規模なデータセットに最適である"
  ],
  "explanationDe": [
    "Bei Leave-one-out wird in jedem Durchlauf nur eine Instanz zum Testen verwendet, alle übrigen Daten fließen ins Training ein – das maximiert die Nutzung der Daten.",
    "Da mehr Daten fürs Training verwendet werden, kann dies die Qualität (Performance) des Klassifikators verbessern.",
    "Die Methode ist deterministisch: Es gibt keine zufällige Auswahl wie bei Holdout oder K-fold, d.h. reproduzierbare Ergebnisse.",
    "Besonders bei kleinen Datensätzen ist LOOCV vorteilhaft, da keine Daten verschwendet werden und jede Instanz zur Bewertung beiträgt."
  ],
  "explanationJa": [
    "Leave-one-outでは、1回の検証ごとに1つのデータだけをテスト用に使い、残りすべてを学習に使います。これにより、学習に使用するデータ量を最大限に確保できます。",
    "多くのデータで学習できるため、モデルの性能（分類精度）が向上する可能性があります。",
    "また、ランダムな分割がないため、結果が安定しており、再現性があります（決定論的）。",
    "小規模なデータセットにとって、1つ1つのデータが貴重なので、すべてを効率的に使えるLOOCVは特に有効です。"
  ],
  "originalSlideText": "– Vorteile:\n  – Nutzung der maximal möglichen Datenmenge für das Training\n  – Dadurch kann es zur Steigerung der Klassifikatorperformanz kommen\n  – Deterministisch (kein random sampling notwendig)\n  – Optimal für kleinere Datensätze",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 29,
  "questionDe": "(s17)Nennen Sie vier Nachteile der Leave-one-out Kreuzvalidierung.",
  "questionJa": "Leave-one-out交差検証（LOOCV）の欠点を4つ挙げよ。",
  "answerDe": [
    "Sehr hohe Rechenzeit",
    "Unpraktisch für große Datensätze",
    "Kann nicht stratifiziert werden",
    "Kann zu irreführender Fehlerrate führen (z. B. 100 % bei echter Rate 50 %)"
  ],
  "answerJa": [
    "計算時間が非常に長い",
    "大規模なデータセットには不向きである",
    "層化（クラスの分布の維持）ができない",
    "誤った誤差率になることがある（例：真の誤差50％でも100％と評価される）"
  ],
  "explanationDe": [
    "Da das Modell n-mal trainiert und getestet wird (für n Datenpunkte), ist der Zeitaufwand sehr hoch – besonders bei großen Datensätzen.",
    "Für Datensätze mit Tausenden Instanzen ist LOOCV oft rechnerisch unmöglich.",
    "LOOCV ist nicht stratifiziert: Es wird nicht garantiert, dass die Klassenverteilung in jedem Training ausgeglichen ist.",
    "Beispiel: Wenn jede Instanz zu einer anderen Klasse gehört, kann das Modell eine Klasse 'ignorieren' und trotzdem eine hohe Fehlerquote liefern – z. B. berechnete Fehlerrate 100 % trotz realer 50 %."
  ],
  "explanationJa": [
    "LOOCVではデータの数n回モデルを学習・評価する必要があるため、特にデータ数が多い場合、膨大な計算時間がかかります。",
    "データが数千件以上あるようなケースでは、現実的に使うのが難しいこともあります。",
    "また、この方法ではクラス分布を均等に保つ「層化」ができません。つまり、学習データにおけるクラスのバランスが崩れる可能性があります。",
    "例えば、2クラスが半々のデータであっても、モデルが常に多数クラスだけを予測すると、誤差率が100％になるという極端なケースも起こり得ます。"
  ],
  "originalSlideText": "– Nachteile:\n  – Rechenzeit!\n  – Unmöglich für große Datensätze\n  – Kann nicht stratifiziert werden\n    – Garantiert nicht stratifiziertes Ergebnis\n  – Annahme: Datensatz mit gleicher Anzahl von Instanzen für 2 Klassen\n    – Berechne die Mehrheitsklasse:\n      – Echter Fehlerrate: 50%\n      – Berechnete Fehlerrate: 100%",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 30,
  "questionDe": "(s18) Was ist das Prinzip des Bootstrappings in der Evaluation?",
  "questionJa": "ブートストラップ法とは、評価においてどのような原理で行われるか？",
  "answerDe": [
    "Bootstrapping verwendet Sampling mit Ersatz",
    "Frühere Verfahren arbeiteten ohne Ersatz",
    "Variante: 0.632 Bootstrap"
  ],
  "answerJa": [
    "ブートストラップは復元抽出（同じデータを複数回選べる）を用いる",
    "従来の手法（ホールドアウトや交差検証）は非復元抽出であった",
    "0.632ブートストラップというバリエーションもある"
  ],
  "explanationDe": [
    "Beim Bootstrapping wird ein Trainingsdatensatz erzeugt, indem man n-mal mit Ersatz aus n Originalinstanzen zieht.",
    "Das heißt, manche Instanzen erscheinen mehrmals, andere gar nicht. Dies unterscheidet sich von Methoden wie Holdout oder Kreuzvalidierung, wo ohne Ersatz gezogen wird.",
    "Die Variante „0.632 Bootstrap“ besagt, dass etwa 63,2 % der Instanzen im Mittel im Trainingsdatensatz auftauchen."
  ],
  "explanationJa": [
    "ブートストラップ法では、n個の元データから復元抽出によりn回データを選び、訓練データを作ります。",
    "このとき、同じデータが複数回選ばれたり、一度も選ばれないものも出てきます。この点が、非復元抽出（1回選んだら再使用しない）を使う交差検証やホールドアウト法と大きく異なります。",
    "0.632ブートストラップでは、平均して全体の約63.2％のデータが訓練データに含まれるとされています。"
  ],
  "originalSlideText": "– Bootstrapping\n– Sampling mit Ersatz\n– Vorherige Verfahren wählten Datenpunkte ohne Ersatz\n– Variante: 0.632 bootstrap",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 31,
  "questionDe": "(s18) Wie werden Trainings- und Testdaten beim Bootstrapping gebildet?",
  "questionJa": "ブートストラップ法では、どのように訓練データとテストデータが分けられるか？",
  "answerDe": [
    "Ein Datensatz mit n Instanzen wird n-mal mit Ersatz gesampelt",
    "Der Trainingsdatensatz enthält n Instanzen, teils mehrfach",
    "Nicht gewählte Instanzen bilden den Testdatensatz"
  ],
  "answerJa": [
    "n個のデータからn回、復元抽出によってサンプリングを行う",
    "訓練データはn個のサンプルで構成され、一部は重複する",
    "一度も選ばれなかったデータはテストデータとして使われる"
  ],
  "explanationDe": [
    "Beim Bootstrapping wird aus einem Ursprungsdatensatz mit n Instanzen ein Trainingsdatensatz durch n Ziehungen mit Ersatz gebildet.",
    "Dadurch entstehen Duplikate: Einige Instanzen tauchen mehrmals auf, andere keinmal.",
    "Die Instanzen, die nie gezogen wurden, verwendet man als Testdaten zur Leistungsbewertung des Modells."
  ],
  "explanationJa": [
    "元のn個のデータから、復元抽出（同じデータが選ばれる可能性あり）でn回データを選びます。",
    "その結果、あるデータが複数回含まれる一方で、まったく含まれないデータも出てきます。",
    "訓練データはこのn個の抽出結果で構成され、使われなかったデータはテスト用に利用されます。"
  ],
  "originalSlideText": "– Ein Datensatz mit n Instanzen wird n mal mit Ersatz gesampelt\n– Liefert einen Trainingsdatensatz, welcher n Instanzen hat\n– Nutzt einige Instanzen im neuen Datensatz mehrfach\n– Ungenutzte Instanzen werden dann im Testdatensatz genutzt",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 32,
  "questionDe": "(s19) Welche Wahrscheinlichkeit hat eine Instanz, bei Bootstrapping nicht gewählt zu werden, und wie ergibt sich daraus der 0.632-Faktor?",
  "questionJa": "Bootstrappingにおいて、1つのインスタンスが選ばれない確率はいくらか？またそれが0.632という値とどう関係するか？",
  "answerDe": [
    "Wahrscheinlichkeit, gewählt zu werden: 1/n",
    "Wahrscheinlichkeit, nicht gewählt zu werden: 1 - 1/n",
    "n Ziehungen mit Ersatz → Wahrscheinlichkeit, nie gewählt zu werden: (1 - 1/n)^n",
    "Grenzwert für großes n: ≈ e⁻¹ ≈ 0.368",
    "→ 36.8 % nicht im Trainingssatz, also 63.2 % im Trainingssatz"
  ],
  "answerJa": [
    "1回で選ばれる確率は1/n",
    "選ばれない確率は1 - 1/n",
    "これをn回繰り返すと、1つのデータが一度も選ばれない確率は (1 - 1/n)^n",
    "nが大きいとき、これはe⁻¹ ≈ 0.368に近づく",
    "→ 約36.8%は訓練データに含まれず、残り63.2%が含まれる（0.632法）"
  ],
  "explanationDe": [
    "Beim Bootstrapping zieht man n-mal mit Ersatz aus einem Datensatz mit n Instanzen.",
    "Die Wahrscheinlichkeit, dass eine bestimmte Instanz in einem Ziehversuch nicht gezogen wird, beträgt 1 - 1/n.",
    "Wenn man n Ziehungen macht, ist die Wahrscheinlichkeit, dass eine Instanz nie gezogen wird, (1 - 1/n)^n.",
    "Für große n nähert sich dieser Wert dem Grenzwert e⁻¹ ≈ 0.368.",
    "Das bedeutet: Im Mittel werden ca. 36.8 % der Instanzen nicht in den Trainingssatz aufgenommen – entsprechend 63.2 % schon (→ 0.632 Bootstrap)."
  ],
  "explanationJa": [
    "ブートストラップでは、n個のデータからn回の復元抽出を行います。",
    "1つのデータが1回の抽出で選ばれない確率は「1 - 1/n」で、これがn回続く確率は (1 - 1/n)^n です。",
    "nが大きくなると、この確率は e⁻¹（約0.368）に近づきます。",
    "つまり、平均して約36.8%のデータは1回も選ばれず、残り63.2%が1回以上訓練データとして使われることになります。",
    "この63.2%という値が『0.632ブートストラップ法』の由来です。"
  ],
  "originalSlideText": "– Jede Instanz hat eine Wahrscheinlichkeit von:\n  – 1/n, um gezogen zu werden\n  – 1 - 1/n, um nicht gezogen zu werden\n– Jedes Item kann n mal gezogen werden\n– Wahrscheinlichkeit, dass eine Instanz nicht gezogen wird:\n  (1 - 1/n)^n ≈ e⁻¹ = 0.368",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 33,
  "questionDe": "(s19) Wie verteilen sich Trainings- und Testdaten beim Bootstrapping?",
  "questionJa": "Bootstrappingでは、訓練データとテストデータはどのような割合で分けられるか？",
  "answerDe": [
    "Trainingsdatensatz enthält ca. 63.2 % der Instanzen",
    "Testdatensatz enthält ca. 36.8 % der Instanzen",
    "Einige Instanzen sind mehrfach im Trainingssatz vertreten"
  ],
  "answerJa": [
    "訓練データには全体の約63.2%のインスタンスが含まれる",
    "残りの約36.8%はテストデータに使われる",
    "訓練データには同じインスタンスが複数回現れることがある"
  ],
  "explanationDe": [
    "Weil etwa 36.8 % der Instanzen bei n Ziehungen mit Ersatz im Mittel nicht gewählt werden, bleiben diese für den Testdatensatz übrig.",
    "Daher bestehen Trainingsdaten beim Bootstrapping aus etwa 63.2 % der Originalinstanzen – wobei einige mehrfach vorkommen können.",
    "Das bedeutet auch, dass das Modell nicht die volle Diversität des Originals sieht, aber dennoch auf vielen Varianten trainiert wird."
  ],
  "explanationJa": [
    "n回の復元抽出を行った結果、平均して36.8%のデータが一度も選ばれず、これらがテストデータに回されます。",
    "訓練データには全体の約63.2%のインスタンスが含まれますが、同じデータが重複して含まれることもあります。",
    "これにより、全データを使ったように見えて、実際には一部のデータが何度も学習に使われるという特性があります。"
  ],
  "originalSlideText": "– Trainingsdatensatz\n  – 63.2% Instanzen\n– Testdatensatz\n  – 36.8% Instanzen\n– Einige Instanzen sind mehrfach im Trainingsdatensatz vertreten und ergeben so n Instanzen",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 34,
  "questionDe": "(s20) Warum ist die Fehlerratenschätzung beim Bootstrapping pessimistisch und wie kann man sie verbessern?",
  "questionJa": "Bootstrappingでの誤差率の推定が悲観的（低め）になるのはなぜか？また、それをどのように補うか？",
  "answerDe": [
    "Nur 63 % der Daten werden für Training verwendet (vs. 90 % bei 10-fold)",
    "Fehlerrate ist dadurch oft pessimistisch",
    "Idee: kombiniere Testfehler mit Modellfehler auf Trainingsdaten",
    "Modellfehler ist aber oft zu optimistisch",
    "Daher sollte er nicht alleine verwendet werden"
  ],
  "answerJa": [
    "訓練データとして使われるのは約63％で、10分割交差検証の90％より少ない",
    "そのため、誤差率が高く出てしまいがち（悲観的）",
    "そこで、テスト誤差とモデルの訓練誤差を組み合わせて補うという工夫がある",
    "ただし訓練誤差は楽観的すぎるため、単独では使うべきではない"
  ],
  "explanationDe": [
    "Beim Bootstrapping basiert die Leistungsschätzung auf einem Modell, das nur mit ca. 63 % der Daten trainiert wurde.",
    "Dadurch wird die Fehlerrate auf dem Testdatensatz tendenziell überschätzt (pessimistisch).",
    "Um das auszugleichen, kombiniert man diesen Testfehler mit dem Fehler, den das Modell auf den Trainingsdaten macht.",
    "Allerdings ist der Trainingsfehler meistens zu optimistisch – daher wird empfohlen, ihn nur im Gewicht mit dem Testfehler zu verwenden."
  ],
  "explanationJa": [
    "ブートストラップでは、データの約63％しか訓練に使われないため、モデルが十分に学習できず、テスト誤差が高く（＝悲観的に）出やすくなります。",
    "そこで補完策として、テスト誤差と訓練データ上の誤差（モデル誤差）を組み合わせるという方法が考案されました。",
    "ただし、訓練誤差は楽観的すぎる傾向があるため、これ単体では使わず、テスト誤差と適切に重みづけして使うのがポイントです。"
  ],
  "originalSlideText": "– Schätzung der Fehlerrate ist pessimistisch\n  – 63% Instanzen gegenüber der 90% Instanzen der 10-fold Kreuzvalidierung\n– Idee: Kombiniere des Testdatensatzfehler mit dem Fehler des Models\n  – Normalerweise zu optimistisch\n  – Sollte nicht alleine genutzt werden",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 35,
  "questionDe": "(s20) Wie berechnet man die Bootstrap-Fehlerrate und warum wird das Verfahren wiederholt?",
  "questionJa": "ブートストラップによる誤差率（エラー率）はどのように計算するか？また、なぜ繰り返し行う必要があるか？",
  "answerDe": [
    "Formel: e = 0.632 × Fehler auf Testdaten + 0.368 × Fehler auf Trainingsdaten",
    "Kombiniert pessimistische und optimistische Fehler",
    "Man wiederholt das Bootstrapping mehrmals",
    "Dann berechnet man den Durchschnitt über alle Wiederholungen"
  ],
  "answerJa": [
    "計算式：e = 0.632 × テストデータ上の誤差 + 0.368 × 訓練データ上の誤差",
    "悲観的な評価と楽観的な評価をバランスよく組み合わせる",
    "ブートストラップを何度も繰り返す必要がある",
    "すべての結果の平均を最終的な評価として用いる"
  ],
  "explanationDe": [
    "Die Bootstrap-Fehlerrate kombiniert den Fehler auf Testdaten (pessimistisch) mit dem Fehler auf Trainingsdaten (optimistisch).",
    "Die Gewichtung 0.632 und 0.368 stammt aus der Wahrscheinlichkeit, ob eine Instanz im Training erscheint oder nicht.",
    "Weil ein einzelner Bootstrap-Durchlauf zufällig ist, wiederholt man das Verfahren viele Male.",
    "Danach mittelt man über alle Fehlerraten, um eine stabile Schätzung zu bekommen."
  ],
  "explanationJa": [
    "ブートストラップ法では、テストデータ上の誤差（悲観的）と訓練データ上の誤差（楽観的）を組み合わせたエラー率を計算します。",
    "組み合わせ比（0.632と0.368）は、それぞれのインスタンスが訓練データに含まれるか否かの確率から来ています。",
    "ただし、1回のブートストラップでは結果が不安定なので、複数回繰り返して評価します。",
    "すべての誤差率の平均を取ることで、より信頼性の高いモデル評価が可能になります。"
  ],
  "originalSlideText": "– Bootstrap Fehlerrate:\n  e = 0.632 e_test instances + 0.368 ⋅ e_training instances\n– Wiederhole das bootstrapping mehrmals\n– Berechne den Durchschnitt über alle Wiederholungen",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 36,
  "questionDe": "(s21) Nennen Sie einen Vorteil des Bootstrappings.",
  "questionJa": "Bootstrappingの利点を1つ挙げよ。",
  "answerDe": [
    "Sehr gut geeignet für sehr kleine Datensätze"
  ],
  "answerJa": [
    "非常に小さいデータセットに対して有効な手法である"
  ],
  "explanationDe": [
    "Bootstrapping verwendet Wiederholungen und Ziehen mit Ersatz, was bei kleinen Datenmengen besonders nützlich ist.",
    "Bei kleinen Datensätzen stehen oft nicht genug Daten zur Verfügung, um sie sinnvoll in Trainings- und Testdaten aufzuteilen.",
    "Durch mehrfaches Ziehen mit Ersatz kann das Modell trotzdem auf ausreichend vielen Daten trainiert werden."
  ],
  "explanationJa": [
    "Bootstrappingは、同じデータを繰り返し使えるという特徴があるため、データ数が少ない場合にも効果的です。",
    "小規模データでは通常の方法では訓練・テストに分けにくいですが、Bootstrappingなら擬似的に大きなサンプルを作ることができます。",
    "そのため、特に小さいデータセットでの評価に向いています。"
  ],
  "originalSlideText": "– Vorteil\n  – Eine der beste Lösungen für sehr kleine Datensätze",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 37,
  "questionDe": "(s21) Warum liefert Bootstrapping in manchen Fällen schlechte Ergebnisse?",
  "questionJa": "なぜBootstrappingは一部のケースで誤った（低すぎる）誤差評価をしてしまうのか？",
  "answerDe": [
    "Bei zwei gleich großen Klassen kann der Trainingsfehler 0 % sein",
    "Fehlerratenschätzung wird dadurch zu niedrig (z. B. 31.6 %)",
    "Tatsächliche Fehlerrate liegt aber bei 50 %"
  ],
  "answerJa": [
    "クラスが2つあり、それぞれの数が等しい場合に問題が起こる",
    "訓練誤差が0％になると、誤差率の推定が31.6％と実際より低くなる",
    "しかし実際の誤差率は50％であり、評価が過小になる"
  ],
  "explanationDe": [
    "Ein Problem kann entstehen, wenn der Datensatz zwei Klassen mit gleicher Anzahl an Instanzen enthält.",
    "Wenn das Modell auf dem Trainingsdatensatz perfekt (0 % Fehler) arbeitet, fließt dieser optimistische Wert in die Formel ein: e = 0.632 × Testfehler + 0.368 × 0.",
    "Das führt dazu, dass die geschätzte Fehlerrate (hier: 31.6 %) deutlich niedriger ist als die tatsächliche (50 %)."
  ],
  "explanationJa": [
    "2クラスが同じ数だけあるようなデータセットでは、訓練データ上で完璧な分類ができてしまう（誤差率0％）ことがあります。",
    "ブートストラップの誤差率計算式では、訓練誤差が0％だと過度に低い値が出てしまい、実際の誤差率とズレが生じます。",
    "このスライドでは、実際の誤差率は50％なのに、計算式から出た値は31.6％で過小評価になってしまった例が示されています。"
  ],
  "originalSlideText": "– Nachteile\n  – Liefert schlechte Ergebnisse für spezielle Fälle\n  – Annahme:\n    – Zwei Klassen\n    – Gleiche Anzahl von Instanzen für jede Klasse\n  – e_training instances = 0\n  – Schätzung der Fehlerrate:\n    0.632 · 50% + 0.368 · 0% = 31.6%\n  – Echte Fehlerrate: 50%",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 38,
  "questionDe": "(s18–21) Erklären Sie das Prinzip des Bootstrappings. Welcher Wert wird häufig verwendet und warum?",
  "questionJa": "（試験類題）Bootstrappingの基本的な仕組みを説明せよ。よく使われる「0.632」は何を意味し、なぜ使われるのか？",
  "answerDe": [
    "Bootstrapping verwendet Ziehen mit Zurücklegen (Sampling mit Ersatz)",
    "Ein Datensatz mit n Instanzen wird n-mal gesampelt",
    "Im Schnitt erscheinen 63.2 % der Instanzen im Trainingsdatensatz",
    "Die restlichen 36.8 % dienen als Testdaten",
    "Daher stammt der Begriff „0.632 bootstrap“"
  ],
  "answerJa": [
    "Bootstrappingでは、復元抽出（同じデータを繰り返し選べる）を行う",
    "n個のデータからn回ランダムにサンプリングして訓練データを作る",
    "平均して63.2%のデータが訓練データに含まれる",
    "残りの36.8%はテストデータとして使われる",
    "この63.2%という割合から「0.632 bootstrap」と呼ばれる"
  ],
  "explanationDe": [
    "Bootstrapping ist eine Methode zur Abschätzung der Modellgüte, bei der aus einem vorhandenen Datensatz mit n Instanzen n Stichproben gezogen werden – und zwar mit Zurücklegen.",
    "Das bedeutet: Nach jeder Ziehung kommt die gezogene Instanz wieder zurück in den Pool und kann erneut gezogen werden.",
    "Einige Instanzen erscheinen daher mehrmals, andere gar nicht. Die Wahrscheinlichkeit, dass eine bestimmte Instanz bei keinem der n Züge gezogen wird, beträgt (1 - 1/n)^n.",
    "Für große n nähert sich dieser Wert e⁻¹ ≈ 0.368. Das heißt: Im Durchschnitt erscheinen etwa 63.2 % der Instanzen im Trainingsdatensatz – und 36.8 % nicht.",
    "Diese 36.8 % werden als Testdaten verwendet. Die Methode kombiniert die Fehler auf diesen Testdaten (die realistisch, aber manchmal pessimistisch sind) mit dem Trainingsfehler, um eine ausgeglichene Schätzung zu erhalten.",
    "Daraus ergibt sich die 0.632-Formel: e = 0.632 × Fehler auf Testdaten + 0.368 × Fehler auf Trainingsdaten."
  ],
  "explanationJa": [
    "Bootstrappingは、手元にあるn個のデータからn回、**復元抽出**（＝同じデータを何回でも選べる）を行って、新しい訓練用データを作る方法です。",
    "例えば、n = 100のとき、1つのデータ（例：ID=23）が3回選ばれることもあれば、別のデータ（ID=42）が一度も選ばれないこともあります。",
    "このとき「あるデータが1回も選ばれない確率」は (1 - 1/n)^n で求められ、nが大きいときは e^(-1) ≈ 0.368（約36.8%）に近づきます。",
    "つまり、データのうち約**63.2%が訓練データに含まれ**、残り**36.8%は一度も使われず、テストデータに回せる**のです。",
    "この63.2%という割合がよく使われるため、手法全体を「0.632ブートストラップ」と呼びます。",
    "この方法では、訓練データのエラー（しばしば楽観的すぎる）とテストデータのエラー（やや悲観的）を組み合わせて、現実的なエラー率を算出できます。",
    "例えば： e = 0.632 × テスト誤差 + 0.368 × 訓練誤差 のような形です。"
  ],
  "originalSlideText": "– Bootstrapping\n– Sampling mit Ersatz\n– Wahrscheinlichkeit, dass eine Instanz nicht gezogen wird: (1 - 1/n)^n ≈ e⁻¹ ≈ 0.368\n– Trainingsdatensatz: 63.2% Instanzen\n– Testdatensatz: 36.8% Instanzen\n– Einige Instanzen mehrfach im Training\n– e = 0.632 e_test + 0.368 e_train",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 39,
  "questionDe": "(s22) Wie kann man verschiedene Data Mining Verfahren sinnvoll vergleichen? Welche Probleme treten auf und wie kann man sie lösen?",
  "questionJa": "異なるデータマイニング手法を適切に比較するにはどうすればよいか？その際に生じる問題と解決策は何か？",
  "answerDe": [
    "Nutze z. B. Kreuzvalidierung zur Fehlerabschätzung",
    "Wähle das Verfahren mit der geringsten Fehlerrate",
    "Problem: Fehlerrate kann unzuverlässig sein",
    "Lösung: Statistische Tests auf Basis von Konfidenzintervallen"
  ],
  "answerJa": [
    "誤差率の見積もりには交差検証（Cross-Validation）などを使う",
    "誤差が最も小さい手法を選ぶのが一般的",
    "問題点：誤差率の見積もりが正確でないことがある",
    "対策：信頼区間に基づく統計的検定を用いて比較する"
  ],
  "explanationDe": [
    "Wenn man mehrere Data Mining Verfahren vergleichen möchte, ist es üblich, die Fehlerrate (z. B. durch Kreuzvalidierung) als Maßstab zu verwenden.",
    "Dabei wählt man oft das Verfahren mit der geringsten geschätzten Fehlerrate.",
    "Jedoch ist diese Schätzung selbst fehleranfällig – sie basiert auf Stichproben und kann zufällig schwanken.",
    "Insbesondere bei neuen Verfahren oder kleinen Datensätzen kann die Fehlerrate nicht repräsentativ sein.",
    "Daher ist es besser, zusätzlich statistische Tests einzusetzen, die auf Konfidenzintervallen beruhen.",
    "Ein Beispiel: Wenn die Fehlerraten zweier Verfahren zu nah beieinander liegen, aber deren Konfidenzintervalle sich überschneiden, ist kein signifikanter Unterschied vorhanden.",
    "Solche Tests helfen, zu entscheiden, ob ein beobachteter Unterschied tatsächlich relevant ist oder nur auf Zufall beruht."
  ],
  "explanationJa": [
    "複数のデータマイニング手法を比較するとき、一般的には「誤分類率（エラー率）」を基準にします。",
    "たとえば、交差検証（Cross-Validation）を使ってそれぞれの手法の誤差を推定し、一番エラーの少ない手法を選ぶという方法です。",
    "しかし、ここで問題になるのは「そのエラー率自体が不正確な可能性がある」という点です。",
    "特にデータが少ない場合や、新しい手法では、誤差の推定が不安定になりがちです。",
    "このような場合、エラー率の大小だけで判断するのではなく、「信頼区間（confidence interval）」に基づいた統計的検定を行うことで、結果の信頼性を高めることができます。",
    "たとえば、2つの手法の誤差率が似ていても、その信頼区間が重なっているなら「有意差がない」と判断できます。",
    "つまり、統計的検定は「その違いが本当に意味のあるものか、それとも偶然か」を判断するのに有効です。"
  ],
  "originalSlideText": "- Vergleich verschiedener Data Mining Verfahren\n- Simple Methode:\n  – Nutze zum Beispiel Kreuzvalidierung\n  – Nutze dann das Verfahren mit der geringsten Fehlerrate\n- Problem:\n  – Geschätzte Fehlerrate kann aber nicht korrekt sein\n  – Wie kann man beurteilen, dass ein Verfahren besser als das andere ist?\n- Insbesondere für neue Verfahren muss man dies evaluieren\n- Lösung:\n  – Statistische Tests, die auf den Konfidenzintervallen basieren",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 40,
  "questionDe": "(s23) Wann und warum wird der t-Test zum Vergleich von Data Mining Verfahren verwendet?",
  "questionJa": "いつ、なぜデータマイニング手法の比較にt検定（t-Test）を使うのか？",
  "answerDe": [
    "Der t-Test (Student’s t-test) vergleicht die Mittelwerte zweier Verfahren",
    "Wenn Trainings- und Testdaten gleich sind, wird der gepaarte t-Test verwendet",
    "Er wird oft zur statistischen Bewertung von Unterschieden in der Fehlerrate eingesetzt"
  ],
  "answerJa": [
    "t検定（Studentのt検定）は2つの手法の平均誤差を比較するために使う",
    "訓練データとテストデータが同じ場合は「対応のあるt検定（ペアt検定）」を使う",
    "誤差率の差が統計的に有意かを判断するためによく用いられる"
  ],
  "explanationDe": [
    "Der t-Test ist ein statistisches Verfahren, das verwendet wird, um zu beurteilen, ob der Unterschied der Mittelwerte zweier Gruppen signifikant ist.",
    "Im Kontext von Data Mining vergleicht man oft die durchschnittlichen Fehlerraten zweier Algorithmen über mehrere Durchläufe oder Folds.",
    "Wenn dieselben Datenpaare (Trainings- und Testdaten) für beide Verfahren verwendet wurden, spricht man von gepaarten Stichproben – in diesem Fall wird der gepaarte t-Test eingesetzt.",
    "Beispiel: Angenommen, sowohl Verfahren A als auch Verfahren B wurden je 10-mal mit denselben Folds getestet. Dann kann man den Unterschied der Fehler je Fold berechnen und mit dem gepaarten t-Test prüfen, ob dieser Unterschied im Mittel signifikant ist.",
    "Dies ist besonders wichtig, da kleine Abweichungen in der Fehlerrate auch zufällig entstehen können. Der t-Test hilft dabei zu beurteilen, ob die Unterschiede „echt“ sind oder nur Zufall."
  ],
  "explanationJa": [
    "t検定（t-Test）は、2つのグループ（ここでは異なるアルゴリズム）の平均誤差が統計的に意味のある差かどうかを判定するための手法です。",
    "特に交差検証などで、両方の手法を同じデータセットに対して複数回実行した場合、Foldごとの誤差を比較できます。",
    "そのような場合、同じFoldを使っているので「対応のあるデータ」となり、対応のあるt検定（paired t-Test）を使います。",
    "例：手法AとBでそれぞれ10回ずつ交差検証を行い、同じデータで比較したとき、Foldごとの誤差差（Aのエラー − Bのエラー）を取り、その平均の差が統計的に有意かどうかをt検定で調べます。",
    "これは「誤差が少し違う」だけでは信頼できない場合に、単なる偶然ではなく本当に有意な差かを確かめるのに役立ちます。"
  ],
  "originalSlideText": "- Vergleich verschiedener Data Mining Verfahren\n- Nutzung des t-Tests (auch bekannt als Student’s t-test)\n- Wenn der Trainingsdatensatz und der Testdatensatz in beiden Verfahren gleich sind, wird der gepaarte t-Test verwendet\n- Evaluierung wird später erklärt\n- Wurde für die Visualisierung auch angepasst, ist aber generell anwendbar",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 41,
  "questionDe": "(s24) Wie unterscheidet sich die Bewertung von Wahrscheinlichkeitsvorhersagen von der klassischen Fehlerbewertung?",
  "questionJa": "確率予測の評価は、従来の単純な誤り判定とどのように異なるのか？",
  "answerDe": [
    "Klassisch wurde nur überprüft, ob die Vorhersage korrekt oder falsch ist",
    "Dafür wurde oft die 0-1 Verlustfunktion verwendet",
    "Viele Verfahren geben aber auch Wahrscheinlichkeiten an (z. B. Naive Bayes)",
    "Solche Wahrscheinlichkeiten sind nützlich, wenn Ergebnisse weiterverarbeitet werden"
  ],
  "answerJa": [
    "従来の方法では、予測が正解か不正解かだけを判定していた",
    "この評価には0-1損失関数（正解なら0、誤りなら1）が使われていた",
    "しかし、多くの学習手法は確率を出力する（例：ナイーブベイズ）",
    "確率の出力は、結果を次の処理に使いたいときに役立つ"
  ],
  "explanationDe": [
    "In klassischen Klassifikationsaufgaben prüft man, ob ein Modell die richtige Klasse vorhergesagt hat. War die Vorhersage korrekt, ist der Fehler 0 – sonst 1.",
    "Das nennt man 0-1 Verlustfunktion. Diese Methode ist einfach und funktioniert in vielen Fällen gut.",
    "Jedoch geben viele moderne Lernverfahren nicht nur die Klasse, sondern auch die Wahrscheinlichkeit für jede Klasse aus – z. B. Naive Bayes oder neuronale Netze.",
    "Solche Wahrscheinlichkeiten sind besonders hilfreich, wenn die Entscheidung nicht binär getroffen wird oder wenn man die Vorhersage in nachfolgenden Verarbeitungsschritten (z. B. Risikoanalyse, Ensemble-Methoden) verwenden möchte.",
    "Beispiel: Ein Modell sagt mit 90% Wahrscheinlichkeit „Ja“ und mit 10% „Nein“. Auch wenn es ‚Ja‘ als Klasse ausgibt, ist es hilfreich zu wissen, wie sicher es ist."
  ],
  "explanationJa": [
    "従来の分類問題では、モデルが予測したクラスが正解かどうかだけを見て評価していました。",
    "正解していれば損失（エラー）は0、間違っていれば1とする「0-1損失関数」が使われます。これは非常にシンプルで、多くの状況ではうまく機能します。",
    "しかし最近の学習アルゴリズムの多くは、単にクラスを出力するだけでなく、その予測に対する「確率」も出力します。たとえば、ナイーブベイズやニューラルネットなどがそうです。",
    "確率を出力する利点は、「どのくらい確信しているのか」がわかる点です。これは、予測をそのまま使うだけでなく、後の処理（リスク評価、複数モデルの組み合わせなど）に利用したいときにとても有用です。",
    "例：モデルが「はい」を90%の確率、「いいえ」を10%で予測した場合、単に「はい」と予測されたという結果よりも、どれくらい確信しているか（＝90%）という情報が重要になる場合があります。"
  ],
  "originalSlideText": "- Vorhersage von Wahrscheinlichkeiten\n- Bisher wurde nur Korrektheit geprüft\n  – Korrekt im Sinne, dass die Vorhersage mit dem gesetzten Wert übereinstimmt\n  – Ansonsten ist es ein Fehler\n- Das ist in vielen Fällen passend\n- 0-1 Verlustfunktion\n  – Korrekte Vorhersage: loss = 0\n  – Fehlerhafte Vorhersage: loss = 1\n- Viele Lernverfahren geben aber zudem eine Wahrscheinlichkeit für die Vorhersage an\n  – Zum Beispiel Naïve Bayes\n- Nützlich, wenn die Ergebnisse in weiteren Schritten genutzt werden sollen",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 42,
  "questionDe": "(s25) Was ist die quadratische Verlustfunktion zur Bewertung von Wahrscheinlichkeitsvorhersagen?",
  "questionJa": "確率予測を評価するための二乗誤差損失関数とは何か？",
  "answerDe": [
    "Sie bewertet den Unterschied zwischen vorhergesagten Wahrscheinlichkeiten und dem tatsächlichen Ergebnis",
    "Verwendet wird: ∑ (p_j - a_j)²",
    "Fehlerhafte Vorhersage ergibt p_j²",
    "Korrekte Vorhersage ergibt: 1 - 2p_i + p_i²",
    "Für mehrere Instanzen wird summiert"
  ],
  "answerJa": [
    "予測された確率と実際の結果の差を評価するための関数である",
    "計算式：∑ (p_j - a_j)²",
    "誤ったクラスへの予測確率p_jが損失になる（p_j²）",
    "正解クラスへの予測では 1 - 2p_i + p_i²",
    "複数インスタンスでは損失を合計する"
  ],
  "explanationDe": [
    "Die quadratische Verlustfunktion wird verwendet, wenn Vorhersagen Wahrscheinlichkeiten ausdrücken.",
    "Angenommen, es gibt k mögliche Klassen. Der Klassifikator gibt einen Wahrscheinlichkeitsvektor (p₁, ..., p_k) aus, wobei ∑p_i = 1.",
    "Das tatsächliche Ergebnis a_j ist ein sogenannter One-Hot-Vektor: Nur der Eintrag der richtigen Klasse ist 1, alle anderen 0.",
    "Dann wird für jede Klasse j die Differenz (p_j - a_j)² berechnet und aufsummiert.",
    "Für korrekte Vorhersagen ist der Verlust gering, für falsche Vorhersagen ist er größer – je nachdem, wie stark das Modell sich ‚irrt‘.",
    "Beispiel: Wenn die korrekte Klasse eine Wahrscheinlichkeit von 0.9 erhält, ist der Verlust kleiner als wenn sie nur 0.6 erhält."
  ],
  "explanationJa": [
    "この二乗損失関数（quadratische Verlustfunktion）は、分類器が各クラスに対して確率を出力する場合に、その予測の精度を評価するために使います。",
    "クラスがk個あるとすると、モデルは (p₁, ..., p_k) という確率ベクトルを出力し、その総和は1になります。",
    "正解のクラスだけが1、他は0になる「One-hot表現」と呼ばれる実際の結果ベクトル (a₁, ..., a_k) と比較し、(p_j - a_j)² の差を各クラスについて計算し、合計します。",
    "正しいクラスに高い確率を割り当てるほど損失は小さく、間違ったクラスに高い確率を割り当てると損失が大きくなります。",
    "例：正解がクラス2のとき、p₂ = 0.9 なら損失は小さく、p₂ = 0.6 なら損失は大きくなります。"
  ],
  "originalSlideText": "- Vorhersage von Wahrscheinlichkeiten: Quadratische Verlustfunktion\n- Für eine einzelne Instanz\n- Annahme:\n  – k mögliche Ergebnisse\n  – Wahrscheinlichkeitsvektor (p₁, ..., p_k), ∑p_i = 1\n- Tatsächliches Ergebnis: (a₁, ..., a_k)\n  – a_i = {1 if correct class, 0 else}\n- Quadratische Verlustfunktion: ∑ (p_j - a_j)² = 1 - 2p_i + ∑p_j²\n  – Fehlerhafte Vorhersagen: p_j²\n  – Korrekte Vorhersagen: (p_i - 1)² = 1 - 2p_i + p_i²\n- Für mehrere Instanzen wird die Verlustfunktion summiert",
  "explanationImage": "lecture01/lecture08_ex02.png",
  "questionImage": ""
},
{
  "id": 43,
  "questionDe": "(s26) Warum wird die quadratische Verlustfunktion bei Wahrscheinlichkeitsvorhersagen verwendet?",
  "questionJa": "確率予測の評価において、なぜ二乗誤差損失関数が使われるのか？",
  "answerDe": [
    "Die Minimierung des quadratischen Fehlers ist gut erforscht",
    "Sie liefert eine gute Schätzung der wahren Wahrscheinlichkeiten",
    "Häufig verwendet für Wahrscheinlichkeitsvorhersagen"
  ],
  "answerJa": [
    "二乗誤差を最小化する方法はよく研究されており安定している",
    "真の確率に近い予測を出す分類器を評価できる",
    "確率的な予測の評価によく使われる"
  ],
  "explanationDe": [
    "Die quadratische Verlustfunktion wird oft verwendet, weil sie mathematisch einfach zu handhaben ist und gut untersucht wurde.",
    "Sie eignet sich besonders, wenn man Modelle nicht nur nach richtiger/falscher Vorhersage beurteilen will, sondern auch, wie genau die Wahrscheinlichkeiten sind.",
    "Ein guter Klassifikator soll nämlich nicht nur ‚richtig‘ liegen, sondern die Unsicherheit korrekt ausdrücken.",
    "Beispiel: Ein Modell sagt mit 70 % Wahrscheinlichkeit die richtige Klasse voraus. Ein besseres Modell könnte 90 % angeben – das zeigt höhere Sicherheit und führt zu geringerem quadratischen Fehler.",
    "Deshalb wird diese Funktion häufig in probabilistischen Klassifikatoren eingesetzt, etwa beim Naive Bayes oder neuronalen Netzen mit Softmax-Ausgang."
  ],
  "explanationJa": [
    "二乗誤差損失関数は、数理的に扱いやすく、理論的にもよく研究されているため、機械学習モデルの評価で広く使われています。",
    "特に「どのくらい正しく予測したか」だけでなく「どれくらい確信を持って予測したか」も評価したいときに有効です。",
    "例えば、あるモデルが正解クラスに70%の確率を与えた場合よりも、90%とした方が、より正確で自信のある予測と言えます。その違いを損失値として反映できます。",
    "そのため、ナイーブベイズやニューラルネットワーク（ソフトマックス関数を使う）などの確率的分類器で頻繁に利用されます。"
  ],
  "originalSlideText": "- Vorhersage von Wahrscheinlichkeiten: Quadratische Verlustfunktion\n- Minimierung des quadratischen Fehlers ist gut erforscht\n- In diesem Falle soll der Klassifizierer die beste Schätzung der wahren Wahrscheinlichkeiten vornehmen\n- Häufig verwendet zur Vorhersage von Wahrscheinlichkeiten",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 44,
  "questionDe": "(s28) Erklären Sie die Idee hinter der informational loss function für Wahrscheinlichkeitsvorhersagen.",
  "questionJa": "確率予測における informational loss function（情報損失関数）の考え方を説明せよ。",
  "answerDe": [
    "Verwendet wird −log₂(pᵢ), wobei pᵢ die vorhergesagte Wahrscheinlichkeit der korrekten Klasse ist",
    "Einheit ist Bit",
    "Entspricht der Information, die nötig ist, um die tatsächliche Klasse auszudrücken",
    "Negative Log-Likelihood: oft verwendete Form",
    "Kleine Wahrscheinlichkeiten führen zu hohen Verlustwerten"
  ],
  "answerJa": [
    "正解クラスの予測確率 pᵢ に対して −log₂(pᵢ) を用いる",
    "単位はビット",
    "実際のクラスを表すために必要な情報量を意味する",
    "Negative log-likelihood としてよく使われる",
    "予測確率が小さいほど損失は大きくなる"
  ],
  "explanationDe": [
    "Die informational loss function misst, wie viel Information (in Bit) nötig ist, um die tatsächliche Klasse auszudrücken – abhängig davon, wie sicher das Modell war.",
    "Wenn das Modell für die richtige Klasse eine hohe Wahrscheinlichkeit vorhersagt (z. B. 0.9), ist der Verlust −log₂(0.9) ≈ 0.15 Bit – also sehr klein.",
    "Wenn das Modell aber nur 0.1 für die richtige Klasse angibt, ist der Verlust −log₂(0.1) ≈ 3.32 Bit – also groß.",
    "Dieser Verlustwert ist besonders nützlich, wenn man nicht nur korrekte/inkorrekte Vorhersagen unterscheiden will, sondern auch die Zuverlässigkeit der Vorhersagen mit einbeziehen möchte.",
    "Da Wahrscheinlichkeiten kleiner als 1 sind, ergibt der Logarithmus einen negativen Wert – das Minuszeichen kehrt dies um, damit der Verlust positiv ist."
  ],
  "explanationJa": [
    "情報損失関数（informational loss function）は、あるクラスに対する予測の確信度（確率）に応じて、その予測の損失をビット単位で測るものです。",
    "正しいクラスの予測確率が高ければ損失は小さく、低ければ損失は大きくなります。",
    "たとえば、正解クラスの予測確率が0.9なら損失は −log₂(0.9) ≈ 0.15ビットと小さくなり、確信度が高いとみなされます。",
    "一方で、正解クラスの確率が0.1なら −log₂(0.1) ≈ 3.32ビットと大きくなり、予測に自信がなかったことになります。",
    "確率は1未満なので、logの値は負になりますが、それにマイナスをかけて損失が正の値として扱えるようにしています。"
  ],
  "originalSlideText": "- Vorhersage von Wahrscheinlichkeiten: Informational Loss Function\n– −log₂ pᵢ\n– i. Vorhersage ist korrekt\n– Negative log likelihood\n– Modulo eines konstanten Faktors, welcher durch die Basis des Logarithmus bestimmt wird\n– Repräsentiert die Informationen, welche notwendig sind, um die tatsächliche Klasse auszudrücken\n– Einheit: bit\n– Wahrscheinlichkeitsverteilung: p₁, ..., pₖ\n– Minimale Anzahl von bits, die benötigt werden, um die tatsächlich aufgetretene Klasse auszudrücken.\n– Unter Beachtung der gegebenen Wahrscheinlichkeitsverteilung\n– Minuszeichen: Wahrscheinlichkeiten sind kleiner als 1\n– Negative Logarithmen!",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 45,
  "questionDe": "(s29) Wie wird der Erwartungswert der informational loss function berechnet und welche Probleme können dabei auftreten?",
  "questionJa": "informational loss functionの期待値の求め方と、それに関連する問題点を説明せよ。",
  "answerDe": [
    "Erwartungswert: ∑ −pⱼ′ · log₂(pⱼ)",
    "pⱼ′ ist die wahre Wahrscheinlichkeit für Klasse j",
    "Minimum wird erreicht, wenn pⱼ = pⱼ′",
    "Problem: Wenn pⱼ = 0, ist der Verlust unendlich",
    "Dieses Problem heißt zero-frequency problem",
    "Lösung: Laplace Estimator"
  ],
  "answerJa": [
    "期待値は −pⱼ′ · log₂(pⱼ) をクラスごとに足し合わせて求める",
    "pⱼ′ は真の確率、pⱼ はモデルの予測確率",
    "pⱼ = pⱼ′ のとき最小になる",
    "問題：pⱼ = 0 だと損失が ∞ になる",
    "これを zero-frequency problem（ゼロ頻度問題）と呼ぶ",
    "解決策：Laplace推定（平滑化）"
  ],
  "explanationDe": [
    "Der Erwartungswert der informational loss function berücksichtigt alle Klassenwahrscheinlichkeiten und gewichtet sie mit der tatsächlichen Verteilung (p′).",
    "Beispiel: Wenn die wahre Klasse mit 50 % Wahrscheinlichkeit auftritt und das Modell nur 10 % vorhersagt, ist der Beitrag zum Verlust sehr groß.",
    "Das Ziel ist, dass die vorhergesagten Wahrscheinlichkeiten möglichst gut den echten Wahrscheinlichkeiten entsprechen – dann ist der Verlust klein.",
    "Ein großes Problem ist das sogenannte zero-frequency problem: Wenn das Modell einer Klasse eine Wahrscheinlichkeit von 0 gibt, aber diese Klasse in Wirklichkeit vorkommt, wird der Verlust unendlich.",
    "Um dies zu vermeiden, verwendet man zum Beispiel den Laplace Estimator: Dieser fügt künstlich kleine Wahrscheinlichkeiten hinzu, sodass kein Wert exakt 0 wird."
  ],
  "explanationJa": [
    "情報損失関数の期待値は、すべてのクラスについて『真の確率 × 予測確率のlog値』を足し合わせて計算します。",
    "このとき、真の確率と予測確率が一致していれば損失は最小になります。",
    "しかし、もしモデルがあるクラスの確率を0と予測してしまい、実際にはそのクラスが出現した場合、損失は無限大（∞）になります。",
    "これが zero-frequency problem（ゼロ頻度問題）で、特に観測数の少ないデータで起きやすいです。",
    "その対策として、Laplace推定（1を足す平滑化）などを用いて、確率がゼロにならないように調整します。"
  ],
  "originalSlideText": "- Vorhersage von Wahrscheinlichkeiten: Informational Loss Function\n– Beispiel:\n– Kopf oder Zahl braucht 1 bit\n– −log₂ ½ = 1\n– Erwarteter Wert\n– ∑ₖ −pⱼ′ · log₂ pⱼ\n– pⱼ′ ist die wahre Wahrscheinlichkeit für die Klasse j\n– Ausprägung ist minimal, wenn pⱼ = pⱼ′\n– Entropie: Durchschnittliche Information\n– Probleme:\n– Wenn die Wahrscheinlichkeit 0 ist, wird der Information loss ∞\n– Auch bekannt als zero-frequency problem\n– Mögliche Lösung:\n– Laplace estimator",
  "explanationImage": "lecture01/lecture08_ex03.png",
  "questionImage": ""
},
{
  "id": 46,
  "questionDe": "(s30) Welche Unterschiede bestehen zwischen der quadratischen Verlustfunktion und der informational loss function?",
  "questionJa": "二乗誤差損失関数と情報損失関数の違いを挙げよ。",
  "answerDe": [
    "Quadratische Verlustfunktion berücksichtigt alle Wahrscheinlichkeiten.",
    "Information loss function bezieht sich nur auf die Wahrscheinlichkeit der tatsächlichen Klasse.",
    "Obere Schranke bei quadratischer Verlustfunktion: 2.",
    "Information loss function hat keine obere Schranke."
  ],
  "answerJa": [
    "二乗誤差損失関数（quadratische Verlustfunktion）はすべてのクラスの確率を考慮する。",
    "情報損失関数（information loss function）は実際に発生したクラスの確率のみを使う。",
    "二乗誤差損失には上限（最大値）2がある。",
    "情報損失関数には上限がない（理論上無限大になり得る）。"
  ],
  "explanationDe": [
    "Die quadratische Verlustfunktion berechnet den Fehler anhand aller Wahrscheinlichkeiten – auch der falschen Klassen. Das kann sinnvoll sein, wenn man das gesamte Wahrscheinlichkeitsprofil bewerten möchte.",
    "Die informational loss function (z. B. −log₂(p)) bezieht sich ausschließlich auf die Wahrscheinlichkeit der tatsächlich eingetretenen Klasse. Dadurch ist sie direkter auf den 'Ernstfall' fokussiert.",
    "Ein praktischer Unterschied: Der Wert der quadratischen Verlustfunktion ist nach oben durch 2 begrenzt. Bei der informational loss function gibt es hingegen keine obere Grenze – der Verlust kann sehr groß werden, z. B. wenn p = 0.001 → −log₂(0.001) ≈ 10.",
    "Dies bedeutet: Die informational loss function bestraft schlechte Vorhersagen härter und ist empfindlicher gegenüber unsicheren Aussagen."
  ],
  "explanationJa": [
    "二乗誤差損失関数では、正解クラスだけでなく、すべてのクラスに対する予測確率のずれを元に損失を計算します。",
    "これに対して、情報損失関数（たとえば −log₂(p)）は、正解クラスの予測確率だけに注目して損失を計算します。",
    "また、二乗誤差損失関数では損失値の上限が2に制限されますが、情報損失関数には上限がなく、確率が非常に小さいときには損失が非常に大きくなる（例：p=0.001 → −log₂(0.001) ≈ 10）。",
    "そのため、情報損失関数の方が、予測の信頼性が低いときに大きな罰を与えるようになっています。"
  ],
  "originalSlideText": "- Vorhersage von Wahrscheinlichkeiten\n– Welche Verlustfunktion sollte man nutzen?\n– Unterschiede:\nQuadratische Verlustfunktion:\n• Beachtet alle Wahrscheinlichkeiten\n• Obere Schranke: 2\nInformation loss function:\n• Basiert nur auf den Wahrscheinlichkeiten der aktuell auftretenden Klassen\n• Keine obere Schranke",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 47,
  "questionDe": "(s31) Warum können klassische Evaluierungen bei unausgeglichenen Daten problematisch sein?",
  "questionJa": "不均衡なデータセットに対して、従来の評価方法が問題になるのはなぜか？",
  "answerDe": [
    "Klassische Evaluierungen berücksichtigen oft nur die Anzahl der korrekten Vorhersagen (z. B. Fehlerrate).",
    "Falsch klassifizierte Daten, besonders bei kleinen Klassen, werden ignoriert.",
    "Ein Modell kann bei starker Klassenunbalance (z. B. 97 % eine Klasse) auch dann gut abschneiden, wenn es immer nur die Mehrheitsklasse vorhersagt.",
    "Das Ergebnis wirkt dann korrekt (z. B. 97 %), obwohl das Modell keine sinnvolle Unterscheidung trifft."
  ],
  "answerJa": [
    "従来の評価指標（例：誤分類率）は、正解数に偏っており、誤って分類されたデータや少数派のクラスに注意を払わない。",
    "データに偏りがある場合（例えば97%が同じクラス）、常にそのクラスを予測するだけで高い正解率（97%）が得られてしまう。",
    "しかし、そのモデルは実質的に学習をしていないに等しく、有益な予測ができていない。",
    "本当に知りたいのは、出現頻度の低いが重要なクラス（例：病気の陽性など）をどれだけ正確に予測できるかである。"
  ],
  "explanationDe": [
    "Im Beispiel auf der Folie tritt eine Klasse (z. B. negatives Testergebnis) in 97 % der Fälle auf. Ein Modell, das immer diese Klasse vorhersagt, erscheint korrekt.",
    "Aber: In den übrigen 3 % liegt das eigentlich interessante Verhalten – z. B. ein positives Testergebnis.",
    "Wenn diese 3 % ignoriert werden, kann das Modell keine nützlichen Entscheidungen unterstützen.",
    "Deshalb ist es wichtig, alternative Metriken zu verwenden, die auch die Leistung bei kleinen Klassen erfassen (z. B. Sensitivität, Precision/Recall, F1-Score)."
  ],
  "explanationJa": [
    "スライドの例では、あるクラス（例えば陰性）が97%を占めており、モデルが常にそれを予測すれば97%の正解率を達成できる。",
    "しかし、残りの3%にこそ本当に重要な情報（たとえば陽性）が含まれていることが多い。",
    "このような場合、単純な正解率ではモデルの本当の性能を評価できない。",
    "したがって、感度（リコール）やF1スコアなど、少数クラスの性能も評価できる指標を使うべきである。"
  ],
  "originalSlideText": "- Berechnung der Kosten\n– Vorgestellte Evaluierungen beachten nicht falsch klassifizierte Daten\n– Das kann zu fragwürdigen Ergebnissen führen!\n– Annahme: Ein Ergebnis tritt in 97% der Fälle auf\n– Das Modell sagt dieses Ergebnis immer voraus\n– Ergebnis ist zu 97% korrekt\n– Sind die Fälle, in denen das Ergebnis nicht auftritt vielleicht interessanter?",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 48,
  "questionDe": "(s32) Welche Kennzahlen kann man aus der Konfusionsmatrix berechnen?",
  "questionJa": "混同行列（Konfusionsmatrix）から導出される代表的な評価指標は何か？",
  "answerDe": [
    "True Positive Rate (TPR) = TP / (TP + FN): Anteil der korrekt als positiv klassifizierten positiven Fälle.",
    "False Positive Rate (FPR) = FP / (FP + TN): Anteil der fälschlich als positiv klassifizierten negativen Fälle.",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN): Anteil aller korrekt klassifizierten Fälle."
  ],
  "answerJa": [
    "True Positive Rate（真陽性率、感度）= TP / (TP + FN)：実際に陽性であるもののうち、正しく陽性と判定された割合。",
    "False Positive Rate（偽陽性率）= FP / (FP + TN)：実際には陰性なのに、誤って陽性と判定された割合。",
    "Accuracy（正解率）= (TP + TN) / (TP + TN + FP + FN)：全予測のうち、正しく判定された割合。"
  ],
  "explanationDe": [
    "Die Konfusionsmatrix besteht aus vier Feldern: TP (true positive), FP (false positive), FN (false negative), TN (true negative).",
    "Diese vier Werte erlauben die Berechnung vieler Leistungskennzahlen.",
    "True Positive Rate wird auch Sensitivität genannt – wichtig z. B. bei medizinischen Tests.",
    "Accuracy kann bei unausgeglichenen Klassen irreführend sein, da sie stark von der Mehrheitsklasse beeinflusst wird."
  ],
  "explanationJa": [
    "混同行列とは、実際のクラスと予測されたクラスの関係を整理した表で、4つの要素（TP, FP, FN, TN）から成る。",
    "これらを用いてさまざまな性能指標を計算できる。",
    "True Positive Rate（感度）は、例えば病気の検査において重要で、実際に病気の人を正しく検出できる割合を示す。",
    "Accuracy（正解率）は全体的な性能を示すが、クラスに偏りがある場合（例：陽性が非常に少ないなど）は過大評価になりやすい。"
  ],
  "originalSlideText": "- True positive rate: TP / (TP + FN)\n- False positive rate: FP / (FP + TN)\n- Accuracy: (TP + TN) / (TP + TN + FP + FN)",
  "explanationImage": "lecture01/lecture08_ex04.png",
  "questionImage": ""
},
{
  "id": 49,
  "questionDe": "(s33) Wie wird eine Konfusionsmatrix bei Multiklassen-Vorhersagen genutzt?",
  "questionJa": "多クラス分類において、混同行列（confusion matrix）はどのように利用されるか？",
  "answerDe": [
    "Bei Multiklassen-Vorhersagen wird eine zweidimensionale Konfusionsmatrix verwendet.",
    "Jede Zelle in der Matrix gibt an, wie viele Instanzen einer tatsächlichen Klasse (Zeile) einer vorhergesagten Klasse (Spalte) zugeordnet wurden.",
    "Gute Ergebnisse zeigen hohe Werte auf der Diagonalen und niedrige Werte außerhalb.",
    "Die Matrix erlaubt den Vergleich mit Zufallsvorhersagen."
  ],
  "answerJa": [
    "多クラス分類では、2次元の混同行列（confusion matrix）を使用する。",
    "行は実際のクラス、列は予測されたクラスを表し、それぞれのセルには該当するインスタンスの数が入る。",
    "正しい予測が多い場合、対角線上（実際のクラスと予測が一致）に大きな値が並び、対角線以外（誤分類）は小さくなる。",
    "このような行列は、ランダムな予測との比較にも役立つ。"
  ],
  "explanationDe": [
    "Eine Konfusionsmatrix bei Multiklassen erlaubt es, die Leistung eines Modells detailliert zu analysieren.",
    "Die diagonalen Einträge zeigen korrekte Vorhersagen – je höher, desto besser.",
    "Abweichungen von der Diagonale zeigen Fehler – besonders relevant, wenn einige Klassen häufiger falsch klassifiziert werden.",
    "Ein Vergleich gegen eine Zufallsvorhersage zeigt, ob das Modell sinnvoller arbeitet als bloßes Raten."
  ],
  "explanationJa": [
    "多クラス分類では、例えば3クラスなら3×3の行列で、全クラス間の予測精度を詳細に可視化できる。",
    "行列の対角線上（左上から右下）は、正しく分類されたインスタンス数を示す。",
    "対角線以外は、誤って他のクラスに分類されたケースであり、どのクラスで誤りが起きやすいか分析できる。",
    "また、ランダムな予測結果と比較することで、モデルが有効かどうかの判断にも活用される。"
  ],
  "originalSlideText": "- Multiklassen Vorhersage: Nutzung einer 2 dimensionalen confusion Matrix\n- Jede Zelle repräsentiert die Anzahl der Instanzen mit:\n    - Zeile: tatsächliche Klasse\n    - Spalte: vorhergesagte Klasse\n- Gute Ergebnisse:\n    - Große Zahlen auf der Diagonalen\n    - Kleine Zahlen außerhalb\n- Kann gut gegen Zufallsvorhersagen verglichen werden",
  "explanationImage": "",
  "questionImage": ""
},
{
  "id": 50,
  "questionDe": "(s34) Was misst die Kappa-Statistik in der Evaluierung und wie wird sie berechnet?",
  "questionJa": "評価においてカッパ統計量（Kappa-Statistik）は何を測定し、どのように計算されるか？",
  "answerDe": [
    "Die Kappa-Statistik misst, wie viel besser ein Modell vorhersagt als reines Raten.",
    "Sie berechnet sich mit der Formel: (p - r) / (m - r)",
    "Dabei ist:",
    "- p: tatsächliche Anzahl korrekter Vorhersagen",
    "- m: maximale Anzahl korrekter Vorhersagen",
    "- r: erwartete Anzahl zufällig korrekter Vorhersagen",
    "Ein Wert von 100 % bedeutet perfekte Vorhersage, 0 % entspricht der Zufallsrate."
  ],
  "answerJa": [
    "カッパ統計量（Kappa-Statistik）は、モデルがランダムな予測よりもどれだけ良い予測をしているかを示す指標である。",
    "計算式は：(p - r) / (m - r)",
    "ここで：",
    "- p：実際の正解予測数",
    "- m：最大可能な正解数（完璧な予測）",
    "- r：ランダムに予測した場合の期待される正解数",
    "100% は完全な予測を意味し、0% はランダムと同等の性能を意味する。"
  ],
  "explanationDe": [
    "Die Kappa-Statistik korrigiert die Vorhersagegenauigkeit, indem sie zufällige Übereinstimmungen berücksichtigt.",
    "Zum Beispiel kann ein Modell in einem unausgeglichenen Datensatz 97 % Genauigkeit erreichen, einfach durch Vorhersage der Mehrheit.",
    "Kappa erkennt, dass dies nicht über Zufall hinausgeht und gibt in diesem Fall einen Wert nahe 0.",
    "So lässt sich die Aussagekraft der Vorhersage objektiver einschätzen."
  ],
  "explanationJa": [
    "カッパ統計量は、精度だけでは見えない、モデルの“本当の意味での性能”を測る方法である。",
    "例えば、97%のデータが1つのクラスに偏っている場合、すべてそれを予測すれば精度は97%だが、意味のある予測とは言えない。",
    "Kappaはこのような偏りを考慮し、ランダムな予測と比べてどれほど意味があるかを数値化する。",
    "したがって、高いKappa値は「ただのラッキーではなく、有意義な予測ができている」ことを示す。"
  ],
  "originalSlideText": "- Kappa Statistik: (p - r)/(m - r)\n  - p: Vorhersagen\n  - m: Maximal erfolgreiche Vorhersagen\n  - r: Zufällige erfolgreiche Vorhersagen\n- Maximaler Wert: 100%\n- Zufallsvorhersage ergibt 0%\n- Beispiel vom Anfang: Kappa Wert würde bei 0% liegen\n- Kosten sind aber immer noch nicht berücksichtigt!",
  "explanationImage": "lecture01/lecture08_ex05.png",
  "questionImage": ""
},
{
  "id": 51,
  "questionDe": "(s35) Was versteht man unter kostensensitiver Klassifikation und wie wird sie bei der Evaluierung berücksichtigt?",
  "questionJa": "コスト感受性分類とは何か？そして評価時にどのように考慮されるのか？",
  "answerDe": [
    "Bei der kostensensitiven Klassifikation wird berücksichtigt, dass falsche Entscheidungen unterschiedliche Kosten verursachen können.",
    "Eine Kostenmatrix zeigt für jede Kombination aus tatsächlicher und vorhergesagter Klasse die anfallenden Kosten.",
    "Diese Matrix wird nicht bei der Vorhersage, aber bei der Evaluierung verwendet.",
    "Für die Evaluierung werden alle relevanten Zellen der Kostenmatrix aufaddiert, um die Gesamtkosten zu berechnen."
  ],
  "answerJa": [
    "コスト感受性分類とは、分類の誤りごとに異なる損失（コスト）が発生することを考慮した評価方法である。",
    "各セル（実際のクラス × 予測クラス）にコストを割り当てた『コスト行列』を使う。",
    "この行列は予測時には使われないが、モデルの評価時に用いられる。",
    "テストインスタンスに対して、該当するセルのコストを合計し、総コストとして評価する。"
  ],
  "explanationDe": [
    "In der Praxis sind manche Fehler gravierender als andere, z. B. eine falsche Krebsdiagnose.",
    "Ein einfaches Beispiel: Falsch-negativ (Krankheit nicht erkannt) kann gefährlicher sein als falsch-positiv (fälschlich als krank erkannt).",
    "Durch eine Kostenmatrix lassen sich diese Unterschiede abbilden und das Modell realitätsnäher evaluieren.",
    "So kann man Modelle bevorzugen, die zwar weniger akkurat, aber aus Sicht der Gesamtkosten besser sind."
  ],
  "explanationJa": [
    "実社会では、分類ミスの重要度は同じではない。例えば：",
    "- がん患者を見逃す（偽陰性）は、誤って陽性と判断する（偽陽性）よりも重大な結果を招く。",
    "そのようなケースでは『コスト行列』を使って、各誤分類に重みをつけて評価する。",
    "モデルの精度（accuracy）だけでなく、実際に発生する損害の合計を評価指標とすることで、より現実的で適切なモデル選択ができる。"
  ],
  "originalSlideText": "- Kostensensitive Klassifikation\n  - Nutzung einer Kostenmatrix\n  - Jede Zelle repräsentiert die Kosten\n  - Unterschiedliche Zellen können unterschiedliche Kosten haben\n- Kosten werden bei der Vorhersage ignoriert, aber bei der Evaluierung berücksichtigt\n- Summiere alle Zellen der Kostenmatrix für eine Testinstanz auf",
  "questionImage": "",
  "explanationImage": ""
},
{
  "id": 52,
  "questionDe": "(s36) Wie funktioniert kostensensitive Klassifikation mit Wahrscheinlichkeiten?",
  "questionJa": "確率を用いたコスト感受性分類はどのように機能するか？",
  "answerDe": [
    "Man verwendet eine Kostenmatrix, die für jede Kombination aus wahrer und vorhergesagter Klasse die Fehlerkosten enthält.",
    "Für jede mögliche Klassenvorhersage berechnet man den Erwartungswert der Kosten, basierend auf den geschätzten Wahrscheinlichkeiten der Klassen.",
    "Die Vorhersage erfolgt dann für die Klasse, die den geringsten Erwartungswert der Fehlerkosten ergibt.",
    "Dies entspricht der Auswahl der Klasse mit der geringsten gewichteten Fehlerrate."
  ],
  "answerJa": [
    "コスト行列を使って、真のクラスと予測クラスの組み合わせごとの誤りコストを定義する。",
    "各クラスに対する予測確率（例: クラスa, b, cに対して pa, pb, pc）を使って、各クラスに分類した場合の期待誤りコスト（期待値）を計算する。",
    "最も誤りコストが低くなるクラスを最終的な予測として選ぶ。",
    "これは『最も確率が高いクラス』を選ぶのとは異なり、『総合的に誤りが少ないクラス』を選ぶ戦略である。"
  ],
  "explanationDe": [
    "Beispiel: Die Kostenmatrix ist [[0,1,1], [1,0,1], [1,1,0]].",
    "Wenn die geschätzten Wahrscheinlichkeiten z.B. pa=0.1, pb=0.6, pc=0.3 sind, berechnet man für jede Vorhersage die erwarteten Kosten:",
    "- Für Vorhersage a: Fehlerkosten = pb + pc = 0.6 + 0.3 = 0.9",
    "- Für Vorhersage b: Fehlerkosten = pa + pc = 0.1 + 0.3 = 0.4",
    "- Für Vorhersage c: Fehlerkosten = pa + pb = 0.1 + 0.6 = 0.7",
    "→ Also sollte Klasse b vorhergesagt werden, da hier die Fehlerkosten am niedrigsten sind."
  ],
  "explanationJa": [
    "例：コスト行列 [[0,1,1], [1,0,1], [1,1,0]] を使う。",
    "予測確率が pa=0.1, pb=0.6, pc=0.3 のとき、各クラスの誤りコストは以下のように計算される：",
    "- クラスaを予測 → コスト: pb + pc = 0.6 + 0.3 = 0.9",
    "- クラスbを予測 → コスト: pa + pc = 0.1 + 0.3 = 0.4",
    "- クラスcを予測 → コスト: pa + pb = 0.1 + 0.6 = 0.7",
    "→ 最も誤りが少ない（=最もコストが低い）クラスbを予測するのが最適。"
  ],
  "originalSlideText": "- Vorhersage der Klasse mit den geringsten Fehlerkosten\n- Gegeben: Kostenmatrix und Wahrscheinlichkeiten\n- Multipliziere Wahrscheinlichkeitsvektor mit entsprechender Spalte der Kostenmatrix\n- Wähle Klasse mit minimalem Erwartungswert der Kosten",
  "questionImage": "",
  "explanationImage": ""
},
{
  "id": 53,
  "questionDe": "(s37) Wie funktioniert kostensensitive Klassifikation durch Anpassung während des Trainings?",
  "questionJa": "トレーニング中の調整によるコスト感受性分類はどのように機能するか？",
  "answerDe": [
    "Die Kostenmatrix wird in der Trainingsphase verwendet, nicht bei der Vorhersage.",
    "Eine einfache Methode ist es, Instanzen zu duplizieren oder ihre Häufigkeit im Trainingsdatensatz zu variieren.",
    "Viele Lernmethoden erlauben es, Instanzen zu gewichten – z.B. höhere Gewichtung für Instanzen mit hohen Fehlklassifikationskosten.",
    "Die Instanzgewichte können entsprechend der relativen Kosten von False Positives und False Negatives angepasst werden."
  ],
  "answerJa": [
    "トレーニング段階でコスト行列を使用し、予測時にはコストを考慮しない。",
    "単純な方法として、インスタンスの重複やデータセット内での出現頻度の変更がある（コストに応じて多く登場させる）。",
    "多くの学習アルゴリズムでは、インスタンスごとの重み付けが可能。",
    "誤分類（偽陽性や偽陰性）の相対的なコストに応じてインスタンスの重みを調整できる。"
  ],
  "explanationDe": [
    "Beispiel: Wenn das Klassifizieren einer positiven Instanz als negativ sehr teuer ist, kann man diese positiven Instanzen öfter ins Training einfügen.",
    "Oder man nutzt Lernalgorithmen, die Instanzengewichtung unterstützen (z.B. Entscheidungsbäume, SVMs mit Gewichtung).",
    "Das Ziel ist, das Modell so zu trainieren, dass Fehler mit hohen Kosten vermieden werden."
  ],
  "explanationJa": [
    "例：陽性データを陰性と誤判定することが高コストな場合、その陽性データを訓練セットに多く含める。",
    "または、重み付け可能な学習アルゴリズム（例：決定木や重み付きSVM）を使用し、各データの重みをコストに応じて調整する。",
    "目的は、コストの高い誤りが起こりにくいモデルを育てること。"
  ],
  "originalSlideText": "- Nutzung der Kostenmatrix während der Trainingsphase\n- Simple Methode: Variiere die Größen der Instanzen im Trainingsdatensatz\n- Viele Lernmethoden erlauben gewichtete Instanzen",
  "questionImage": "",
  "explanationImage": ""
},
{
  "id": 54,
  "questionDe": "(s38) Wie kann man numerische Vorhersagen evaluieren?",
  "questionJa": "数値予測はどのように評価すればよいか？",
  "answerDe": [
    "Auch bei numerischen Vorhersagen gelten die gleichen Grundprinzipien der Evaluation.",
    "Man vergleicht die vorhergesagten Werte (zum Beispiel: p1, p2, ..., pn) mit den tatsächlichen Werten (a1, a2, ..., an).",
    "Dabei muss die Messung der Fehlerrate an numerische Daten angepasst werden, etwa durch mathematische Fehlermaße."
  ],
  "answerJa": [
    "数値予測にも評価の基本的な考え方は当てはまる。",
    "予測値（例えば p1, p2, ..., pn）と実際の値（a1, a2, ..., an）を比較する。",
    "その際、誤差の測定は数値データに合わせて、数式による評価指標（例えば平均絶対誤差など）を使って行う必要がある。"
  ],
  "explanationDe": [
    "Bei Klassifikationen prüft man einfach, ob das Ergebnis richtig oder falsch war. Aber bei numerischen Vorhersagen ist das nicht ausreichend.",
    "Hier muss man messen, wie stark die Vorhersage vom tatsächlichen Wert abweicht. Das heißt, man berechnet den Fehler zwischen dem vorhergesagten und dem tatsächlichen Wert.",
    "Typische Fehlermaße sind zum Beispiel: absoluter Fehler (Differenz zwischen Vorhersage und Realität), quadratischer Fehler (Fehler wird quadriert), oder Mittelwert der Fehler.",
    "Solche Maße geben eine quantitative Aussage darüber, wie gut oder schlecht das Modell ist."
  ],
  "explanationJa": [
    "分類の場合は、予測が正しいかどうかで判断できるが、数値予測の場合は単純な正誤判定では不十分である。",
    "数値予測では『どのくらい外れているか』を測る必要がある。つまり、予測値と実際の値の差（誤差）を数値で評価する。",
    "代表的な誤差の測定法として、絶対誤差（予測値と実測値の差）、二乗誤差（差を2乗する）などがある。",
    "これらの手法により、モデルの予測精度を具体的に把握することができる。"
  ],
  "originalSlideText": "- Evaluierung numerischer Vorhersagen\n- Grundideen funktionieren auch hier\n- Messung der Fehlerrate muss angepasst werden:\n  - Vorhergesagte Werte in den Testinstanzen: p₁, ..., pₙ\n  - Tatsächliche Werte: a₁, ..., aₙ",
  "questionImage": "",
  "explanationImage": ""
},
{
  "id": 55,
  "questionDe": "(s39) Was ist der mittlere quadratische Fehler und wofür wird er verwendet?",
  "questionJa": "平均二乗誤差とは何か？どのような場面で使われるか？",
  "answerDe": [
    "Der mittlere quadratische Fehler (engl. Mean Squared Error, MSE) ist eine Kennzahl zur Bewertung der Qualität numerischer Vorhersagen.",
    "Er berechnet sich, indem man für jede Instanz die Differenz zwischen dem vorhergesagten Wert (p) und dem tatsächlichen Wert (a) quadriert, diese quadrierten Abweichungen summiert und durch die Anzahl n der Instanzen teilt.",
    "Eine alternative Darstellung ist die Wurzel des mittleren quadratischen Fehlers (engl. Root Mean Squared Error, RMSE), bei der zusätzlich die Quadratwurzel gezogen wird."
  ],
  "answerJa": [
    "平均二乗誤差（MSE）は、数値予測の精度を評価するための指標である。",
    "各データに対して、予測値（p）と実測値（a）の差を2乗し、それをすべてのデータで足し合わせ、データ数nで割ったもの。",
    "また、平方根をとった『二乗平均平方根誤差（RMSE）』もよく用いられる。"
  ],
  "explanationDe": [
    "Der mittlere quadratische Fehler ist eine sehr häufig verwendete Methode zur Bewertung von Regressionsmodellen.",
    "Durch das Quadrieren der Abweichungen werden größere Fehler stärker gewichtet, weshalb MSE empfindlich auf Ausreißer reagiert.",
    "Die Wurzel des mittleren quadratischen Fehlers (RMSE) hat den Vorteil, dass das Ergebnis dieselbe Einheit wie der ursprüngliche Wert hat, was die Interpretation erleichtert.",
    "Mathematisch gesehen ist RMSE besser handhabbar, weil er nicht durch die Quadrate verzerrt wird."
  ],
  "explanationJa": [
    "平均二乗誤差（MSE）は、回帰モデルの評価によく使われる指標である。",
    "誤差を2乗するため、大きな誤差（外れ値）に対して敏感に反応する特性がある。",
    "平方根をとったRMSEは、元の予測値と同じ単位になるため、解釈しやすくなる。",
    "また、RMSEは数式上も扱いやすく、現場でよく使われている。"
  ],
  "originalSlideText": "- Evaluierung numerischer Vorhersagen\n- Mittlerer quadratischer Fehler:\n  (Summe von (p - a)^2 über n Instanzen geteilt durch n)\n  - Wird sehr häufig genutzt\n  - Reagiert empfindlich auf Ausreißer\n- Wurzel der mittleren Fehlerquadratsumme:\n  - Hat die gleiche Dimension wie der vorhergesagte Wert\n  - Mathematisch unproblematischer",
  "questionImage": "",
  "explanationImage": "lecture01/lecture08_ex06.png"
},
{
  "id": 56,
  "questionDe": "(s40) Was ist der mittlere absolute Fehler und wann ist er nützlich?",
  "questionJa": "平均絶対誤差（MAE）とは何か？どのような場合に有用か？",
  "answerDe": [
    "Der mittlere absolute Fehler (MAE) ist der Durchschnitt der absoluten Abweichungen zwischen vorhergesagten und tatsächlichen Werten.",
    "Er wird berechnet, indem man für jede Instanz den absoluten Unterschied |p - a| bildet, diese summiert und durch die Anzahl n der Instanzen teilt.",
    "Er ist robust gegenüber Ausreißern, da keine Quadrierung der Fehler erfolgt."
  ],
  "answerJa": [
    "平均絶対誤差（MAE）は、予測値と実際の値の差の絶対値の平均をとった指標である。",
    "すべてのデータにおいて |p - a| を計算し、それらを足し合わせてデータ数 n で割ることで求められる。",
    "誤差を2乗しないため、外れ値の影響を受けにくいという特徴がある。"
  ],
  "explanationDe": [
    "MAE ist eine häufig verwendete Bewertungsgröße für Regressionsmodelle, insbesondere wenn Ausreißer vorhanden sind.",
    "Da MAE keine Quadrierung beinhaltet, werden große Fehler nicht übermäßig stark gewichtet.",
    "Dies macht MAE robuster, aber unter Umständen auch weniger empfindlich für große Fehler."
  ],
  "explanationJa": [
    "MAEは、回帰モデルの性能評価においてよく用いられる指標の1つ。",
    "誤差の2乗を行わないため、大きな誤差が他と同じように扱われ、全体に与える影響が抑えられる。",
    "そのため、外れ値が含まれる場合にRMSEよりも適しているとされる。"
  ],
  "originalSlideText": "- Mittlerer absoluter Fehler: Summe |p_j - a_j| / n\n- Unempfindlich gegen Ausreißer",
  "questionImage": "",
  "explanationImage": "lecture01/lecture08_ex07.png"
},
{
  "id": 57,
  "questionDe": "(s41) Was ist der relative quadratische Fehler und warum wird er verwendet?",
  "questionJa": "相対二乗誤差とは何か？なぜ使われるのか？",
  "answerDe": [
    "Der relative quadratische Fehler vergleicht die Fehler eines Modells mit der Streuung der tatsächlichen Werte.",
    "Er zeigt, wie viel schlechter oder besser ein Modell im Vergleich zu einer einfachen Mittelwertvorhersage ist.",
    "Er wird berechnet, indem man die quadrierten Vorhersagefehler durch die quadrierten Abweichungen der wahren Werte vom Mittelwert teilt."
  ],
  "answerJa": [
    "相対二乗誤差は、モデルの予測誤差を、実際のデータのばらつき（分散）と比較する指標です。",
    "つまり、単に平均値を使って予測した場合と比べて、モデルの精度がどれほど優れているか・劣っているかを示します。",
    "予測値と実際の値の差の2乗を合計し、それを実データの平均からの差の2乗和で割って求めます。"
  ],
  "explanationDe": [
    "Ein Wert < 1 bedeutet: das Modell ist besser als eine triviale Mittelwertvorhersage.",
    "Ein Wert > 1 bedeutet: das Modell ist schlechter als einfach der Mittelwert.",
    "Sehr hilfreich, um zu beurteilen, ob sich ein Modell überhaupt lohnt."
  ],
  "explanationJa": [
    "値が1未満の場合、モデルは平均値を使った単純な予測よりも良いということになります。",
    "1を超える場合は、むしろ単純に平均値を返す方がマシという意味になります。",
    "この指標は、モデルがどの程度意味のある性能を持つかを判断するのに役立ちます。"
  ],
  "originalSlideText": "- Relativer-quadratischer Fehler: Summe (p_j - a_j)^2 / Summe (a_j - ȧ)^2\n- Relativ zu den Ergebnissen eines simplen Klassifikators",
  "questionImage": "",
  "explanationImage": "lecture01/lecture08_ex08.png"
},
{
  "id": 58,
  "questionDe": "(s41) Was ist die Wurzel des relativen quadratischen Fehlers und wie unterscheidet sie sich vom relativen Fehler?",
  "questionJa": "相対二乗誤差の平方根とは何か？通常の相対誤差と何が違うのか？",
  "answerDe": [
    "Die Wurzel des relativen quadratischen Fehlers ist einfach die Quadratwurzel des relativen Fehlers.",
    "Durch die Wurzel kommt man zurück zur ursprünglichen Einheit der Werte.",
    "So kann man den Fehler direkter interpretieren – z.B. in derselben Einheit wie das Ergebnis (z. B. kg, Euro, Punkte)."
  ],
  "answerJa": [
    "相対二乗誤差の平方根は、相対二乗誤差に平方根をとったものです。",
    "平方根をとることで、誤差の単位が元のデータと同じになります（たとえばkgや点数など）。",
    "これにより、モデルの誤差の大きさがより直感的に理解できるようになります。"
  ],
  "explanationDe": [
    "Die Quadratwurzel hilft, übermäßig große Fehler zu glätten.",
    "Oft wird diese Metrik gewählt, weil sie aussagekräftiger und interpretierbarer ist.",
    "Sie entspricht der Idee des RMSE (Root Mean Squared Error)."
  ],
  "explanationJa": [
    "平方根を取ることで、極端に大きな誤差（外れ値）の影響を和らげることができます。",
    "予測精度を現実的なスケールで比較しやすくなるため、実務でよく使われます。",
    "RMSE（平均二乗誤差の平方根）と同様の考え方です。"
  ],
  "originalSlideText": "- Wurzel des relativen quadratischen Fehlers: sqrt(Summe (p_j - a_j)^2 / Summe (a_j - ȧ)^2)",
  "questionImage": "",
  "explanationImage": ""
},
{
  "id": 59,
  "questionDe": "(s41) Was ist der relative absolute Fehler und wann ist er sinnvoll?",
  "questionJa": "相対絶対誤差とは何か？どのような時に有効か？",
  "answerDe": [
    "Der relative absolute Fehler ist das Verhältnis der Summe der absoluten Vorhersagefehler zur Summe der absoluten Abweichungen vom Mittelwert.",
    "Er zeigt, ob ein Modell besser vorhersagt als eine triviale Mittelwertstrategie.",
    "Kein Quadrieren der Fehler – daher robuster gegen Ausreißer."
  ],
  "answerJa": [
    "相対絶対誤差は、予測値と実際値との差の絶対値の合計を、実際値とその平均との差の絶対値の合計で割ったものです。",
    "モデルが単純に平均値を返す予測よりも優れているかどうかを判断するために使われます。",
    "誤差を二乗しないため、外れ値に対しても頑健です。"
  ],
  "explanationDe": [
    "Ein Wert < 1 → Modell besser als Durchschnitt.",
    "Ein Wert > 1 → Modell schlechter als Mittelwert.",
    "Gut geeignet bei Daten mit Ausreißern oder unregelmäßiger Streuung."
  ],
  "explanationJa": [
    "この値が1未満であれば、モデルの方が単純平均よりも良い予測をしていることになります。",
    "1を超えると、平均を使った予測の方が正確だという意味になります。",
    "データにばらつきや外れ値がある場合でも、相対絶対誤差は安定して使えます。"
  ],
  "originalSlideText": "- Relativer absoluter Fehler: Summe |p_j - a_j| / Summe |a_j - ȧ|",
  "questionImage": "",
  "explanationImage": "lecture01/lecture08_ex09.png"
},
{
  "id": 60,
  "questionDe": "(s42) Was misst der Korrelationskoeffizient bei numerischen Vorhersagen?",
  "questionJa": "数値予測における相関係数は何を測定するか？",
  "answerDe": [
    "Er misst die Stärke des linearen Zusammenhangs zwischen vorhergesagten und tatsächlichen Werten.",
    "Der Wert liegt zwischen -1 (perfekte negative Korrelation) und 1 (perfekte positive Korrelation).",
    "Ein Wert von 0 bedeutet keine lineare Korrelation."
  ],
  "answerJa": [
    "相関係数は、予測値と実測値の間にどの程度の直線的な関係があるかを測定する指標です。",
    "値の範囲は -1（完全な負の相関）から 1（完全な正の相関）までです。",
    "値が 0 の場合は、直線的な相関関係がないことを意味します。"
  ],
  "explanationDe": [
    "Ein Wert von 1 bedeutet, dass die vorhergesagten Werte genau proportional zu den tatsächlichen Werten sind – also eine perfekte Vorhersage im Trend.",
    "Ein Wert von -1 zeigt eine perfekte negative Beziehung: Wenn der echte Wert steigt, sinkt die Vorhersage im gleichen Maße.",
    "Ein Wert von 0 bedeutet, dass es keinen linearen Zusammenhang gibt – die Vorhersagewerte schwanken unabhängig von den echten Werten.",
    "Der Korrelationskoeffizient ist unabhängig von der Skalierung. Wenn man z.B. alle Vorhersagewerte mit 10 multipliziert, bleibt der Wert gleich."
  ],
  "explanationJa": [
    "相関係数が 1 のときは、予測値と実際の値が完全に比例している（傾き1の直線関係）ことを意味します。",
    "相関係数が -1 のときは、予測値と実際の値が逆の動きをしながらも、完全に一直線上に並んでいる状態です。",
    "相関係数が 0 の場合、予測と実測の値に直線的な関係がないことを示します（例：予測は当てずっぽうに近い）。",
    "また、この値はスケーリングの影響を受けません。予測値をすべて2倍しても、相関係数の値は変わりません。"
  ],
  "originalSlideText": "- 1: Perfekte Korrelation\n- 0: Keine Korrelation\n- -1: Perfekte negative Korrelation\n- Unabhängig von Skalierung",
  "questionImage": "",
  "explanationImage": ""
},
{
  "id": 60,
  "questionDe": "(s42) Was misst der Korrelationskoeffizient bei numerischen Vorhersagen?",
  "questionJa": "数値予測における相関係数は何を測定するか？",
  "answerDe": [
    "Er misst die Stärke des linearen Zusammenhangs zwischen vorhergesagten und tatsächlichen Werten.",
    "Der Wert liegt zwischen -1 (perfekte negative Korrelation) und 1 (perfekte positive Korrelation).",
    "Ein Wert von 0 bedeutet keine lineare Korrelation."
  ],
  "answerJa": [
    "相関係数は、予測値と実測値の間にどの程度の直線的な関係があるかを測定する指標です。",
    "値の範囲は -1（完全な負の相関）から 1（完全な正の相関）までです。",
    "値が 0 の場合は、直線的な相関関係がないことを意味します。"
  ],
  "explanationDe": [
    "Ein Wert von 1 bedeutet, dass die vorhergesagten Werte genau proportional zu den tatsächlichen Werten sind – also eine perfekte Vorhersage im Trend.",
    "Ein Wert von -1 zeigt eine perfekte negative Beziehung: Wenn der echte Wert steigt, sinkt die Vorhersage im gleichen Maße.",
    "Ein Wert von 0 bedeutet, dass es keinen linearen Zusammenhang gibt – die Vorhersagewerte schwanken unabhängig von den echten Werten.",
    "Der Korrelationskoeffizient ist unabhängig von der Skalierung. Wenn man z.B. alle Vorhersagewerte mit 10 multipliziert, bleibt der Wert gleich."
  ],
  "explanationJa": [
    "相関係数が 1 のときは、予測値と実際の値が完全に比例している（傾き1の直線関係）ことを意味します。",
    "相関係数が -1 のときは、予測値と実際の値が逆の動きをしながらも、完全に一直線上に並んでいる状態です。",
    "相関係数が 0 の場合、予測と実測の値に直線的な関係がないことを示します（例：予測は当てずっぽうに近い）。",
    "また、この値はスケーリングの影響を受けません。予測値をすべて2倍しても、相関係数の値は変わりません。"
  ],
  "originalSlideText": "- 1: Perfekte Korrelation\n- 0: Keine Korrelation\n- -1: Perfekte negative Korrelation\n- Unabhängig von Skalierung",
  "questionImage": "",
  "explanationImage": "lecture01/lecture08_ex10.png"
},
{
  "id": 62,
  "questionDe": "(s44) Wovon hängt die Wahl der Fehlermessart bei numerischen Vorhersagen ab?",
  "questionJa": "数値予測における誤差評価方法の選択は何に依存するか？",
  "answerDe": [
    "Die Wahl der Fehlermessart hängt vom konkreten Anwendungsfall ab.",
    "Man muss entscheiden, welche Art von Fehler minimiert werden soll.",
    "Auch die Kosten verschiedener Fehlerarten müssen berücksichtigt werden."
  ],
  "answerJa": [
    "どの誤差指標を使うかは、具体的な応用目的によって決まります。",
    "どのタイプの誤差を最小化すべきかを判断する必要があります。",
    "誤差の種類ごとのコスト（損失）も考慮する必要があります。"
  ],
  "explanationDe": [
    "Beispiel: In einer medizinischen Vorhersage könnte ein kleiner Fehler in eine Richtung schwerwiegender sein als in die andere Richtung.",
    "In einem Preisvorhersagemodell könnten sowohl Über- als auch Unterschätzungen gleich wichtig sein – dort ist z.B. der mittlere absolute Fehler sinnvoll.",
    "Oft führen verschiedene Fehlermessarten (z. B. MAE, RMSE, Korrelation) zu ähnlichen Schlussfolgerungen – aber nicht immer!",
    "Deshalb ist es wichtig, die Fehlerart bewusst auf die Fragestellung abzustimmen."
  ],
  "explanationJa": [
    "例えば医療の予測では、過小評価（見逃し）の方が過大評価（誤診）よりも大きな問題となる場合があります。",
    "商品の価格予測では、高く見積もっても安く見積もっても同じくらいの影響があるため、絶対誤差を使うのが適していることもあります。",
    "多くの場合、どの誤差指標を使っても似たような評価結果が得られますが、例外もあります。",
    "したがって、どの誤差が本当に重要なのか、目的や文脈に応じて慎重に選ぶ必要があります。"
  ],
  "originalSlideText": "- Sinn des berechnete Maßes hängt von der Anwendung ab:\n   - Was soll minimiert werden?\n   - Was sind die Kosten der verschiedenen Fehlerarten?\n- Meistens liefern alle Fehlermessarten das gleiche Ergebnis",
  "questionImage": "",
  "explanationImage": ""
}
]